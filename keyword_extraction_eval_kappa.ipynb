{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatically Count Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_excel('data/keyword_extraction_eval_annotator.xlsx')\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to extract keywords and create new DataFrame\n",
    "# def extract_keywords(row):\n",
    "#     keywords = []\n",
    "#     for col in data.columns:\n",
    "#         keywords.extend(row[col].split(', '))\n",
    "#     return pd.Series({'index': row.name, 'keywords': keywords})\n",
    "\n",
    "# # Apply the function to each row of the DataFrame\n",
    "# new_data = data.apply(extract_keywords, axis=1).explode('keywords').reset_index(drop=True)\n",
    "\n",
    "# print(new_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to determine labeling and not labeling counts for each keyword\n",
    "# def determine_labeling(row):\n",
    "#     keyword = row['keywords']\n",
    "#     labeling = 0\n",
    "#     not_labeling = 0\n",
    "    \n",
    "#     # Get the row from data DataFrame based on the index\n",
    "#     data_row = data.iloc[row['index']]\n",
    "    \n",
    "#     # Iterate over each column (Responden) in the data DataFrame\n",
    "#     for col in data.columns[2:]:\n",
    "#         data_row[col] = data_row[col].replace(\",\", \"\") # list keyword tiap responden\n",
    "#         if any(subset in word.split(' ') for word in data_row[col] for subset in keyword ):\n",
    "#         # if any(keyword in word.split(\", \") for word in data_row[col]):\n",
    "#             labeling += 1\n",
    "#         else:\n",
    "#             not_labeling += 1\n",
    "#     return pd.Series({'labeling': labeling, 'not_labeling': not_labeling})\n",
    "\n",
    "# # Apply the function to each row of new_data DataFrame\n",
    "# new_data[['labeling', 'not_labeling']] = new_data.apply(determine_labeling, axis=1)\n",
    "\n",
    "# print(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # hasile\n",
    "\n",
    "# eval_count = new_data[[\"index\", \"keywords\"]]\n",
    "# eval_count.to_excel('data/keyword_extraction_eval_count_dummy.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manually Count Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>keywords</th>\n",
       "      <th>Responden 1</th>\n",
       "      <th>Responden 2</th>\n",
       "      <th>Responden 3</th>\n",
       "      <th>Responden 4</th>\n",
       "      <th>Responden 5</th>\n",
       "      <th>labeling</th>\n",
       "      <th>not_labeling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>automatically generating vocabulary problems</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>generate potential answers</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>investigate and understand the meanings of the...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>repeatedly receive problems about desired words</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>generates problems</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                           keywords  Responden 1  \\\n",
       "0      0       automatically generating vocabulary problems          1.0   \n",
       "1      0                         generate potential answers          1.0   \n",
       "2      0  investigate and understand the meanings of the...          1.0   \n",
       "3      0    repeatedly receive problems about desired words          1.0   \n",
       "4      0                                generates problems           1.0   \n",
       "\n",
       "   Responden 2  Responden 3  Responden 4  Responden 5  labeling  not_labeling  \n",
       "0          1.0          1.0          1.0          1.0         5             0  \n",
       "1          1.0          1.0          1.0          1.0         5             0  \n",
       "2          0.0          0.0          0.0          0.0         1             4  \n",
       "3          0.0          0.0          0.0          0.0         1             4  \n",
       "4          0.0          0.0          0.0          0.0         1             4  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel('data/keyword_extraction_eval_count.xlsx')\n",
    "data_paten = data.loc[data.index.isin(list(range(0, 10)) + list(range(20, 30)))]\n",
    "data_isco = data.loc[data.index.isin(list(range(10, 20)) + list(range(30, 40)))]\n",
    "# data = data[(data['labeling'] > 3) | (data['not_labeling'] > 3)]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fleiss Kappa Each Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>keywords</th>\n",
       "      <th>Responden 1</th>\n",
       "      <th>Responden 2</th>\n",
       "      <th>Responden 3</th>\n",
       "      <th>Responden 4</th>\n",
       "      <th>Responden 5</th>\n",
       "      <th>labeling</th>\n",
       "      <th>not_labeling</th>\n",
       "      <th>pi</th>\n",
       "      <th>k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>automatically generating vocabulary problems</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>generate potential answers</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>investigate and understand the meanings of the...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>repeatedly receive problems about desired words</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>generates problems</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.6</td>\n",
       "      <td>-0.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                           keywords  Responden 1  \\\n",
       "0      0       automatically generating vocabulary problems          1.0   \n",
       "1      0                         generate potential answers          1.0   \n",
       "2      0  investigate and understand the meanings of the...          1.0   \n",
       "3      0    repeatedly receive problems about desired words          1.0   \n",
       "4      0                                generates problems           1.0   \n",
       "\n",
       "   Responden 2  Responden 3  Responden 4  Responden 5  labeling  not_labeling  \\\n",
       "0          1.0          1.0          1.0          1.0         5             0   \n",
       "1          1.0          1.0          1.0          1.0         5             0   \n",
       "2          0.0          0.0          0.0          0.0         1             4   \n",
       "3          0.0          0.0          0.0          0.0         1             4   \n",
       "4          0.0          0.0          0.0          0.0         1             4   \n",
       "\n",
       "    pi     k  \n",
       "0  1.0  1.00  \n",
       "1  1.0  1.00  \n",
       "2  0.6 -0.25  \n",
       "3  0.6 -0.25  \n",
       "4  0.6 -0.25  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# N = 1  # number of data\n",
    "# n = 5  # number of respondent\n",
    "# k = 2  # number of categories\n",
    "\n",
    "# list_k = []\n",
    "# list_pi = []\n",
    "# for index, row in data.iterrows():\n",
    "#     pi = (row['labeling']**2 + row['not_labeling']**2 - n) / (n*(n-1))\n",
    "#     labeling_pj = row['labeling'] / (N*n)\n",
    "#     not_labeling_pj = row['not_labeling'] / (N*n)\n",
    "#     p = 1 / N * pi\n",
    "#     pe = labeling_pj**2 + not_labeling_pj**2\n",
    "#     if pe == 1:\n",
    "#         k = 1  # Handle division by zero in the formula\n",
    "#     else:\n",
    "#         k = (p - pe) / (1 - pe)\n",
    "#     list_pi.append(pi)\n",
    "#     list_k.append(k)\n",
    "\n",
    "# data['pi'] = list_pi\n",
    "# data['k'] = list_k\n",
    "# data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fleiss Kappa All Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p = 0.6555555555555556\n",
      "pe = 0.5158024691358025\n",
      "k = 0.28862825089240174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\oktav\\AppData\\Local\\Temp\\ipykernel_1184\\801953178.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  unique_data_paten['pi'] = list_pi\n"
     ]
    }
   ],
   "source": [
    "# Paten\n",
    "\n",
    "unique_data_paten = data_paten.drop_duplicates() # get unique keywords\n",
    "N = len(unique_data_paten) # number of unique_data_paten\n",
    "n = 5 # number of responden\n",
    "k = 2 # number of category\n",
    "\n",
    "# Calculate pi for each row\n",
    "list_pi = []\n",
    "for index, row in unique_data_paten.iterrows():\n",
    "    n = row['labeling'] + row['not_labeling']\n",
    "    pi = 1 / (n*(n-1)) * (row['labeling']**2 + row['not_labeling']**2 - n)\n",
    "    list_pi.append(pi)\n",
    "\n",
    "# Calculate pj\n",
    "labeling_pj = 1 / (N*n) * unique_data_paten['labeling'].sum()\n",
    "not_labeling_pj = 1 / (N*n) * unique_data_paten['not_labeling'].sum()\n",
    "\n",
    "# Calculate p and pe\n",
    "p = 1 / N * sum(list_pi)\n",
    "pe = labeling_pj**2 + not_labeling_pj**2\n",
    "print(\"p = \" + str(p))\n",
    "print(\"pe = \" + str(pe))\n",
    "\n",
    "# Calculate k\n",
    "k = (p-pe) / (1-pe)\n",
    "print(\"k = \" + str(k))\n",
    "unique_data_paten['pi'] = list_pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p = 0.72\n",
      "pe = 0.608888888888889\n",
      "k = 0.2840909090909088\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\oktav\\AppData\\Local\\Temp\\ipykernel_1184\\2843266570.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  unique_data_isco['pi'] = list_pi\n"
     ]
    }
   ],
   "source": [
    "# ISCO\n",
    "\n",
    "unique_data_isco = data_isco.drop_duplicates() # get unique keywords\n",
    "N = len(unique_data_isco) # number of unique_data_isco\n",
    "n = 5 # number of responden\n",
    "k = 2 # number of category\n",
    "\n",
    "# Calculate pi for each row\n",
    "list_pi = []\n",
    "for index, row in unique_data_isco.iterrows():\n",
    "    n = row['labeling'] + row['not_labeling']\n",
    "    pi = 1 / (n*(n-1)) * (row['labeling']**2 + row['not_labeling']**2 - n)\n",
    "    list_pi.append(pi)\n",
    "\n",
    "# Calculate pj\n",
    "labeling_pj = 1 / (N*n) * unique_data_isco['labeling'].sum()\n",
    "not_labeling_pj = 1 / (N*n) * unique_data_isco['not_labeling'].sum()\n",
    "\n",
    "# Calculate p and pe\n",
    "p = 1 / N * sum(list_pi)\n",
    "pe = labeling_pj**2 + not_labeling_pj**2\n",
    "print(\"p = \" + str(p))\n",
    "print(\"pe = \" + str(pe))\n",
    "\n",
    "# Calculate k\n",
    "k = (p-pe) / (1-pe)\n",
    "print(\"k = \" + str(k))\n",
    "unique_data_isco['pi'] = list_pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 0.7100000000000002\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\oktav\\AppData\\Local\\Temp\\ipykernel_2952\\1565957760.py:18: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  unique_data['pic'] = list_pic\n"
     ]
    }
   ],
   "source": [
    "# # tes tes\n",
    "\n",
    "# import math\n",
    "\n",
    "# def combinations(n):\n",
    "#     if n < 2:\n",
    "#         return 0\n",
    "#     else:\n",
    "#         return math.comb(n, 2)\n",
    "\n",
    "# def average(numbers):\n",
    "#     total = sum(numbers)\n",
    "#     return total / len(numbers)\n",
    "\n",
    "# list_pic = []\n",
    "# for index, row in unique_data.iterrows():\n",
    "#     pic = (combinations(row['labeling']) + combinations(row['not_labeling'])) / combinations(n)\n",
    "#     list_pic.append(pic)\n",
    "\n",
    "# unique_data['pic'] = list_pic\n",
    "# k = average(list_pic)\n",
    "# print(\"k = \" + str(k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cohen's Kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def observed_agreement(i, j):\n",
    "#     confusion_matrix = pd.crosstab(data['Responden '+str(i)], data['Responden '+str(j)])\n",
    "#     diagonal_sum = sum(confusion_matrix.iloc[i,i] for i in range(len(confusion_matrix)))\n",
    "#     return diagonal_sum / len(data)\n",
    "\n",
    "# def chance_agreement(i, j):\n",
    "#     df = data[['Responden '+str(i), 'Responden '+str(j)]]\n",
    "#     sum_rows = [sum(row) for row in df.values]\n",
    "#     sum_columns = [sum(col) for col in df.values.transpose()]\n",
    "#     p_i = sum([row * row for row in sum_rows]) / (sum(sum_rows) ** 2)\n",
    "#     p_j = sum([col * col for col in sum_columns]) / (sum(sum_columns) ** 2)\n",
    "#     return p_i * p_j\n",
    "\n",
    "# def count_kappa(i, j):\n",
    "#     # Calculate observed agreement\n",
    "#     observed_agr = observed_agreement(i, j)\n",
    "#     # Calculate chance agreement\n",
    "#     chance_agr = chance_agreement(i, j)\n",
    "#     # Calculate Cohen's Kappa\n",
    "#     kappa = (observed_agr - chance_agr) / (1 - chance_agr)\n",
    "#     return kappa\n",
    "    \n",
    "# for i in range(1, 6):  # Looping pertama dari 1 sampai 5\n",
    "#     for j in range(i+1, 6):  # Looping kedua dari nilai i sampai 5\n",
    "#         k = count_kappa(i, j)\n",
    "#         print(f'nilai kappa responden {i} dengan responden {j} = {k}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
