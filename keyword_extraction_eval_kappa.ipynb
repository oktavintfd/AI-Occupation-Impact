{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automatically Count Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data = pd.read_excel('data/keyword_extraction_eval_annotator.xlsx')\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to extract keywords and create new DataFrame\n",
    "# def extract_keywords(row):\n",
    "#     keywords = []\n",
    "#     for col in data.columns:\n",
    "#         keywords.extend(row[col].split(', '))\n",
    "#     return pd.Series({'index': row.name, 'keywords': keywords})\n",
    "\n",
    "# # Apply the function to each row of the DataFrame\n",
    "# new_data = data.apply(extract_keywords, axis=1).explode('keywords').reset_index(drop=True)\n",
    "\n",
    "# print(new_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Function to determine labeling and not labeling counts for each keyword\n",
    "# def determine_labeling(row):\n",
    "#     keyword = row['keywords']\n",
    "#     labeling = 0\n",
    "#     not_labeling = 0\n",
    "    \n",
    "#     # Get the row from data DataFrame based on the index\n",
    "#     data_row = data.iloc[row['index']]\n",
    "    \n",
    "#     # Iterate over each column (Responden) in the data DataFrame\n",
    "#     for col in data.columns[2:]:\n",
    "#         data_row[col] = data_row[col].replace(\",\", \"\") # list keyword tiap responden\n",
    "#         if any(subset in word.split(' ') for word in data_row[col] for subset in keyword ):\n",
    "#         # if any(keyword in word.split(\", \") for word in data_row[col]):\n",
    "#             labeling += 1\n",
    "#         else:\n",
    "#             not_labeling += 1\n",
    "#     return pd.Series({'labeling': labeling, 'not_labeling': not_labeling})\n",
    "\n",
    "# # Apply the function to each row of new_data DataFrame\n",
    "# new_data[['labeling', 'not_labeling']] = new_data.apply(determine_labeling, axis=1)\n",
    "\n",
    "# print(new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # hasile\n",
    "\n",
    "# eval_count = new_data[[\"index\", \"keywords\"]]\n",
    "# eval_count.to_excel('data/keyword_extraction_eval_count_dummy.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manually Count Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>keywords</th>\n",
       "      <th>Responden 1</th>\n",
       "      <th>Responden 2</th>\n",
       "      <th>Responden 3</th>\n",
       "      <th>Responden 4</th>\n",
       "      <th>Responden 5</th>\n",
       "      <th>labeling</th>\n",
       "      <th>not_labeling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>automatically generating vocabulary problems</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>generate potential answers</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>automatically generating vocabulary problems</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>generate potential answers of high difficulty ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>inputting target words</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                           keywords  Responden 1  \\\n",
       "0      0       automatically generating vocabulary problems          1.0   \n",
       "1      0                         generate potential answers          1.0   \n",
       "5      0       automatically generating vocabulary problems          1.0   \n",
       "7      0  generate potential answers of high difficulty ...          1.0   \n",
       "8      0                             inputting target words          0.0   \n",
       "\n",
       "   Responden 2  Responden 3  Responden 4  Responden 5  labeling  not_labeling  \n",
       "0          1.0          1.0          1.0          1.0         5             0  \n",
       "1          1.0          1.0          1.0          1.0         5             0  \n",
       "5          1.0          1.0          1.0          1.0         5             0  \n",
       "7          1.0          1.0          1.0          1.0         5             0  \n",
       "8          1.0          1.0          0.0          1.0         3             2  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel('data/keyword_extraction_eval_count.xlsx')\n",
    "data = data[data['labeling'] >= 3]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fleiss Kappa Each Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>keywords</th>\n",
       "      <th>Responden 1</th>\n",
       "      <th>Responden 2</th>\n",
       "      <th>Responden 3</th>\n",
       "      <th>Responden 4</th>\n",
       "      <th>Responden 5</th>\n",
       "      <th>labeling</th>\n",
       "      <th>not_labeling</th>\n",
       "      <th>pi</th>\n",
       "      <th>k</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>automatically generating vocabulary problems</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>generate potential answers</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>automatically generating vocabulary problems</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>generate potential answers of high difficulty ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>inputting target words</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0.4</td>\n",
       "      <td>-0.25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                           keywords  Responden 1  \\\n",
       "0      0       automatically generating vocabulary problems          1.0   \n",
       "1      0                         generate potential answers          1.0   \n",
       "5      0       automatically generating vocabulary problems          1.0   \n",
       "7      0  generate potential answers of high difficulty ...          1.0   \n",
       "8      0                             inputting target words          0.0   \n",
       "\n",
       "   Responden 2  Responden 3  Responden 4  Responden 5  labeling  not_labeling  \\\n",
       "0          1.0          1.0          1.0          1.0         5             0   \n",
       "1          1.0          1.0          1.0          1.0         5             0   \n",
       "5          1.0          1.0          1.0          1.0         5             0   \n",
       "7          1.0          1.0          1.0          1.0         5             0   \n",
       "8          1.0          1.0          0.0          1.0         3             2   \n",
       "\n",
       "    pi     k  \n",
       "0  1.0  1.00  \n",
       "1  1.0  1.00  \n",
       "5  1.0  1.00  \n",
       "7  1.0  1.00  \n",
       "8  0.4 -0.25  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N = 1  # number of data\n",
    "n = 5  # number of respondent\n",
    "k = 2  # number of categories\n",
    "\n",
    "list_k = []\n",
    "list_pi = []\n",
    "for index, row in data.iterrows():\n",
    "    pi = (row['labeling']**2 + row['not_labeling']**2 - n) / (n*(n-1))\n",
    "    labeling_pj = row['labeling'] / (N*n)\n",
    "    not_labeling_pj = row['not_labeling'] / (N*n)\n",
    "    p = 1 / N * pi\n",
    "    pe = labeling_pj**2 + not_labeling_pj**2\n",
    "    if pe == 1:\n",
    "        k = 1  # Handle division by zero in the formula\n",
    "    else:\n",
    "        k = (p - pe) / (1 - pe)\n",
    "    list_pi.append(pi)\n",
    "    list_k.append(k)\n",
    "\n",
    "data['pi'] = list_pi\n",
    "data['k'] = list_k\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fleiss Kappa All Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p = 0.757471264367816\n",
      "pe = 0.7577675019450685\n",
      "k = -0.0012229472908516271\n"
     ]
    }
   ],
   "source": [
    "unique_data = data.drop_duplicates() # get unique keywords\n",
    "N = len(unique_data) # number of unique_data\n",
    "n = 5 # number of responden\n",
    "k = 2 # number of category\n",
    "\n",
    "# Calculate pi for each row\n",
    "list_pi = []\n",
    "for index, row in unique_data.iterrows():\n",
    "    n = row['labeling'] + row['not_labeling']\n",
    "    pi = 1 / (n*(n-1)) * (row['labeling']**2 + row['not_labeling']**2 - n)\n",
    "    list_pi.append(pi)\n",
    "\n",
    "# Calculate pj\n",
    "labeling_pj = 1 / (N*n) * unique_data['labeling'].sum()\n",
    "not_labeling_pj = 1 / (N*n) * unique_data['not_labeling'].sum()\n",
    "\n",
    "# Calculate p and pe\n",
    "p = 1 / N * sum(list_pi)\n",
    "pe = labeling_pj**2 + not_labeling_pj**2\n",
    "print(\"p = \" + str(p))\n",
    "print(\"pe = \" + str(pe))\n",
    "\n",
    "# Calculate k\n",
    "k = (p-pe) / (1-pe)\n",
    "print(\"k = \" + str(k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cohen's Kappa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def observed_agreement(i, j):\n",
    "#     confusion_matrix = pd.crosstab(data['Responden '+str(i)], data['Responden '+str(j)])\n",
    "#     diagonal_sum = sum(confusion_matrix.iloc[i,i] for i in range(len(confusion_matrix)))\n",
    "#     return diagonal_sum / len(data)\n",
    "\n",
    "# def chance_agreement(i, j):\n",
    "#     df = data[['Responden '+str(i), 'Responden '+str(j)]]\n",
    "#     sum_rows = [sum(row) for row in df.values]\n",
    "#     sum_columns = [sum(col) for col in df.values.transpose()]\n",
    "#     p_i = sum([row * row for row in sum_rows]) / (sum(sum_rows) ** 2)\n",
    "#     p_j = sum([col * col for col in sum_columns]) / (sum(sum_columns) ** 2)\n",
    "#     return p_i * p_j\n",
    "\n",
    "# def count_kappa(i, j):\n",
    "#     # Calculate observed agreement\n",
    "#     observed_agr = observed_agreement(i, j)\n",
    "#     # Calculate chance agreement\n",
    "#     chance_agr = chance_agreement(i, j)\n",
    "#     # Calculate Cohen's Kappa\n",
    "#     kappa = (observed_agr - chance_agr) / (1 - chance_agr)\n",
    "#     return kappa\n",
    "    \n",
    "# for i in range(1, 6):  # Looping pertama dari 1 sampai 5\n",
    "#     for j in range(i+1, 6):  # Looping kedua dari nilai i sampai 5\n",
    "#         k = count_kappa(i, j)\n",
    "#         print(f'nilai kappa responden {i} dengan responden {j} = {k}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
