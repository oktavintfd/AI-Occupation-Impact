{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\oktav\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\oktav\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\oktav\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\oktav\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\oktav\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.chunk import RegexpParser\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keyword Extraction by NLP"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The present invention relates to a method for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The present disclosure is directed to methods,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>An anti-theft method for an oil tank truck bas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The invention provides an artificial intellige...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Systems and methods for using machine learning...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data\n",
       "0  The present invention relates to a method for ...\n",
       "1  The present disclosure is directed to methods,...\n",
       "2  An anti-theft method for an oil tank truck bas...\n",
       "3  The invention provides an artificial intellige...\n",
       "4  Systems and methods for using machine learning..."
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data\n",
    "\n",
    "data = pd.read_excel('data/keyword_extraction_eval_data.xlsx')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check missing value\n",
    "\n",
    "print(data.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The present invention relates to a method for ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The present disclosure is directed to methods,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>An anti-theft method for an oil tank truck bas...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The invention provides an artificial intellige...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Systems and methods for using machine learning...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>The present invention relates to an artificial...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The present invention relates to an apparatus ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Provided are a device for updating a first art...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>An artificial intelligence (AI) system for det...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>The invention provides a method and a system f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Managing directors and chief executives formul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Mining supervisors oversee mining and quarryin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Senior government officials advise governments...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Medical and pathology laboratory technicians p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Environmental protection professionals study a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Cartographers and surveyors determine the exac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Physicists and astronomers conduct research an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Dental assistants and therapists provide basic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Management and organization analysts assist or...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Economists conduct research, monitor data, ana...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>The utility model provides a fruit quality con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>The invention discloses a method, a device and...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>A system and method for selecting and presenti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>An artificial intelligence server for controll...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>A system for predicting a non-fraud dispute us...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>A user console for controlling a remote surgic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>The invention provides a method for calculatin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Provided herein as a steerable surgical roboti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>The present invention relates to an image reco...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>The invention discloses a human body falling d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Meter readers and vending-machine collectors s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Street and related service workers provide a v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Travel guides accompany individuals or groups ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>Railway brakers, signallers and shunters take ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Packing, bottling and labelling machine operat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>Information and communications technology user...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>Handicraft workers in wood, basketry and relat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>Concrete placers, concrete finishers and relat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>Subsistence fishers, hunters, trappers and gat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Subsistence mixed crop and livestock farmers g...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 data\n",
       "0   The present invention relates to a method for ...\n",
       "1   The present disclosure is directed to methods,...\n",
       "2   An anti-theft method for an oil tank truck bas...\n",
       "3   The invention provides an artificial intellige...\n",
       "4   Systems and methods for using machine learning...\n",
       "5   The present invention relates to an artificial...\n",
       "6   The present invention relates to an apparatus ...\n",
       "7   Provided are a device for updating a first art...\n",
       "8   An artificial intelligence (AI) system for det...\n",
       "9   The invention provides a method and a system f...\n",
       "10  Managing directors and chief executives formul...\n",
       "11  Mining supervisors oversee mining and quarryin...\n",
       "12  Senior government officials advise governments...\n",
       "13  Medical and pathology laboratory technicians p...\n",
       "14  Environmental protection professionals study a...\n",
       "15  Cartographers and surveyors determine the exac...\n",
       "16  Physicists and astronomers conduct research an...\n",
       "17  Dental assistants and therapists provide basic...\n",
       "18  Management and organization analysts assist or...\n",
       "19  Economists conduct research, monitor data, ana...\n",
       "20  The utility model provides a fruit quality con...\n",
       "21  The invention discloses a method, a device and...\n",
       "22  A system and method for selecting and presenti...\n",
       "23  An artificial intelligence server for controll...\n",
       "24  A system for predicting a non-fraud dispute us...\n",
       "25  A user console for controlling a remote surgic...\n",
       "26  The invention provides a method for calculatin...\n",
       "27  Provided herein as a steerable surgical roboti...\n",
       "28  The present invention relates to an image reco...\n",
       "29  The invention discloses a human body falling d...\n",
       "30  Meter readers and vending-machine collectors s...\n",
       "31  Street and related service workers provide a v...\n",
       "32  Travel guides accompany individuals or groups ...\n",
       "33  Railway brakers, signallers and shunters take ...\n",
       "34  Packing, bottling and labelling machine operat...\n",
       "35  Information and communications technology user...\n",
       "36  Handicraft workers in wood, basketry and relat...\n",
       "37  Concrete placers, concrete finishers and relat...\n",
       "38  Subsistence fishers, hunters, trappers and gat...\n",
       "39  Subsistence mixed crop and livestock farmers g..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # remove missing value (tidak perlu karena kolom title and abstract tidak memiliki missing value)\n",
    "\n",
    "# data.dropna(inplace=True)\n",
    "# data.head()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    the present invention relates to a method for ...\n",
       "1    the present disclosure is directed to methods,...\n",
       "2    an anti-theft method for an oil tank truck bas...\n",
       "3    the invention provides an artificial intellige...\n",
       "4    systems and methods for using machine learning...\n",
       "Name: lowered, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lowering text\n",
    "data['lowered']= data['data'].apply(lambda x: x.lower())\n",
    "\n",
    "# Print the updated DataFrame\n",
    "data['lowered'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['invention', 'provides', 'artificial', 'intelligence', 'ai', 'system', 'categorizing', 'events'], ['said', 'ai', 'system', 'comprising', 'first', 'state', 'second', 'state'], ['wherein', 'said', 'ai', 'system', 'first', 'state', 'categorizing', 'events', 'first', 'category', 'type'], ['upon', 'categorizing', 'first', 'event', 'predefined', 'category', 'said', 'first', 'category', 'type'], ['said', 'ai', 'system', 'set', 'said', 'second', 'state'], ['said', 'second', 'state', 'said', 'ai', 'system', 'set', 'categorizing', 'subsequent', 'events', 'second', 'category', 'type']]\n"
     ]
    }
   ],
   "source": [
    "# Function to tokenize each sentence, tokenize each word from sentence, then remove punctuation and sopword\n",
    "def tokenize_and_remove_punctuation(text):\n",
    "    # Define stopword\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    # Tokenize each sentence\n",
    "    sentences = re.split(r'(?<=[.!?,;])\\s+', text)\n",
    "    \n",
    "    # Tokenize each word in each sentence, remove punctuation, and remove stopword\n",
    "    tokenized_sentences = []\n",
    "    for sentence in sentences:\n",
    "        tokens = word_tokenize(sentence)\n",
    "        # Remove punctuation\n",
    "        tokens = [token for token in tokens if token not in string.punctuation]\n",
    "        # Remove stopword\n",
    "        tokens = [token for token in tokens if token not in stop_words]\n",
    "        tokenized_sentences.append(tokens)\n",
    "    return tokenized_sentences\n",
    "\n",
    "# Tokenize each sentence and remove punctuation & stopword\n",
    "data['tokenized'] = data['lowered'].apply(tokenize_and_remove_punctuation)\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(data['tokenized'][3])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('invention', 'NN'), ('provides', 'VBZ'), ('artificial', 'JJ'), ('intelligence', 'NN'), ('ai', 'NN'), ('system', 'NN'), ('categorizing', 'VBG'), ('events', 'NNS')], [('said', 'VBD'), ('ai', 'NN'), ('system', 'NN'), ('comprising', 'VBG'), ('first', 'JJ'), ('state', 'NN'), ('second', 'JJ'), ('state', 'NN')], [('wherein', 'NN'), ('said', 'VBD'), ('ai', 'NN'), ('system', 'NN'), ('first', 'JJ'), ('state', 'NN'), ('categorizing', 'VBG'), ('events', 'NNS'), ('first', 'JJ'), ('category', 'NN'), ('type', 'NN')], [('upon', 'IN'), ('categorizing', 'VBG'), ('first', 'JJ'), ('event', 'NN'), ('predefined', 'VBD'), ('category', 'NN'), ('said', 'VBD'), ('first', 'JJ'), ('category', 'NN'), ('type', 'NN')], [('said', 'VBD'), ('ai', 'NN'), ('system', 'NN'), ('set', 'VBN'), ('said', 'VBD'), ('second', 'JJ'), ('state', 'NN')], [('said', 'VBD'), ('second', 'JJ'), ('state', 'NN'), ('said', 'VBD'), ('ai', 'JJ'), ('system', 'NN'), ('set', 'VBN'), ('categorizing', 'VBG'), ('subsequent', 'JJ'), ('events', 'NNS'), ('second', 'JJ'), ('category', 'NN'), ('type', 'NN')]]\n"
     ]
    }
   ],
   "source": [
    "# Function to perform POS tagging on each token\n",
    "def pos_tag_tokens(tokenized_sentences):\n",
    "    pos_tagged_sentences = []\n",
    "    for sentence_tokens in tokenized_sentences:\n",
    "        pos_tags = pos_tag(sentence_tokens)\n",
    "        pos_tagged_sentences.append(pos_tags)\n",
    "    return pos_tagged_sentences\n",
    "\n",
    "# Perform POS tagging on tokenized sentences\n",
    "data['pos_tagged'] = data['tokenized'].apply(pos_tag_tokens)\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(data['pos_tagged'][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[('invention', 'NN'), ('provide', 'VBZ'), ('artificial', 'JJ'), ('intelligence', 'NN'), ('ai', 'NN'), ('system', 'NN'), ('categorize', 'VBG'), ('event', 'NNS')], [('say', 'VBD'), ('ai', 'NN'), ('system', 'NN'), ('comprise', 'VBG'), ('first', 'JJ'), ('state', 'NN'), ('second', 'JJ'), ('state', 'NN')], [('wherein', 'NN'), ('say', 'VBD'), ('ai', 'NN'), ('system', 'NN'), ('first', 'JJ'), ('state', 'NN'), ('categorize', 'VBG'), ('event', 'NNS'), ('first', 'JJ'), ('category', 'NN'), ('type', 'NN')], [('upon', 'IN'), ('categorize', 'VBG'), ('first', 'JJ'), ('event', 'NN'), ('predefined', 'VBD'), ('category', 'NN'), ('say', 'VBD'), ('first', 'JJ'), ('category', 'NN'), ('type', 'NN')], [('say', 'VBD'), ('ai', 'NN'), ('system', 'NN'), ('set', 'VBN'), ('say', 'VBD'), ('second', 'JJ'), ('state', 'NN')], [('say', 'VBD'), ('second', 'JJ'), ('state', 'NN'), ('say', 'VBD'), ('ai', 'JJ'), ('system', 'NN'), ('set', 'VBN'), ('categorize', 'VBG'), ('subsequent', 'JJ'), ('event', 'NNS'), ('second', 'JJ'), ('category', 'NN'), ('type', 'NN')]]\n"
     ]
    }
   ],
   "source": [
    "# Function to lemmatize tokens\n",
    "def lemmatize_tokens(pos_tagged_sentences):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_sentences = []\n",
    "    for sentence_tags in pos_tagged_sentences:\n",
    "        lemmatized_tokens = [(lemmatizer.lemmatize(token, pos=get_wordnet_pos(pos_tag)), pos_tag) for token, pos_tag in sentence_tags]\n",
    "        lemmatized_sentences.append(lemmatized_tokens)\n",
    "    return lemmatized_sentences\n",
    "\n",
    "# Function to map POS tags to WordNet POS tags\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return nltk.corpus.wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return nltk.corpus.wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return nltk.corpus.wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return nltk.corpus.wordnet.ADV\n",
    "    else:\n",
    "        return nltk.corpus.wordnet.NOUN  # Default to noun if POS tag not recognized\n",
    "\n",
    "# Lemmatize the tokens in 'pos_tagged_sentences' column\n",
    "data['lemmatized'] = data['pos_tagged'].apply(lemmatize_tokens)\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(data['lemmatized'][3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS Chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0     [(give, problem), (correspond, word), (inputti...\n",
       "1     [(direct, method), (prepare, food), (prepare, ...\n",
       "2     [(base, machine), (learn, comprises), (follow,...\n",
       "3     [(categorize, event), (say, ai), (say, ai), (c...\n",
       "4     [(use, machine), (predict, risk), (pose, patie...\n",
       "5     [(analyze, conversation), (collect, data), (an...\n",
       "6     [(provide, surface), (mold, condition), (provi...\n",
       "7     [(provide, device), (ai, model), (follow, step...\n",
       "8     [(include, computer), (run, computer), (label,...\n",
       "9     [(follow, step), (extract, target), (improve, ...\n",
       "10    [(manage, director), (formulate, review), (ent...\n",
       "11       [(quarry, operation), (supervise, coordinate)]\n",
       "12      [(advise, government), (establish, government)]\n",
       "13                              [(obtain, information)]\n",
       "14               [(develop, plan), (minimize, prevent)]\n",
       "15                               [(construct, feature)]\n",
       "16    [(conduct, research), (improve, develop), (con...\n",
       "17               [(diseases, disorder), (accord, care)]\n",
       "18                             [(assist, organization)]\n",
       "19    [(conduct, research), (develop, model), (formu...\n",
       "20    [(base, computer), (place, fruit), (side, conv...\n",
       "21    [(detect, paper), (accord, data), (accord, dat...\n",
       "22    [(present, advertisement), (receive, input), (...\n",
       "23    [(control, plurality), (include, communication...\n",
       "24    [(base, communication), (comprise, data), (rec...\n",
       "25    [(comprise, seat), (seat, configuration), (ele...\n",
       "26    [(calculate, road), (follow, step), (obtain, t...\n",
       "27    [(provide, herein), (position, catheter), (com...\n",
       "28    [(relate, image), (sense, device), (determine,...\n",
       "29    [(fall, detection), (base, computer), (fall, e...\n",
       "30                     [(vend, machine), (park, meter)]\n",
       "31    [(provide, variety), (include, cleaning), (was...\n",
       "32                                                   []\n",
       "33    [(take, charge), (operate, signal), (roll, sto...\n",
       "34                                   [(label, machine)]\n",
       "35              [(resolve, issue), (provide, guidance)]\n",
       "36                     [(weave, paint), (make, wicker)]\n",
       "37                    [(make, form), (mould, concrete)]\n",
       "38                                    [(provide, food)]\n",
       "39                                    [(provide, food)]\n",
       "Name: pattern_webb, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# POS chunk new pattern (Pak Indra)\n",
    "\n",
    "# define pattern\n",
    "pattern_raharjana = r'''Chunk: {<VB\\w*>+<.|IN|CC|PRP\\w*>*<DT>*<NN\\w*|RB>+}'''\n",
    "pattern_webb = r'''Chunk: {<VB\\w*><NN\\w*>}'''\n",
    "pattern_johann = r'''Chunk: {<VB\\w*><NN\\w*>|<VB\\w*><PRP\\w*><NN\\w*>|<VB\\w*><NN\\w*><NN\\w*>|<VB\\w*><JJ\\w*><NN\\w*>|<VB\\w*><DT><NN\\w*>|<VB\\w*><NN\\w*><IN><NN\\w*>|<VB\\w*><IN><JJ\\w*><NN\\w*>|<VB\\w*><PRP\\w*><JJ\\w*><NN\\w*>}'''\n",
    "\n",
    "def extract(tagged_texts, pattern):\n",
    "    chunk_parser = RegexpParser(pattern)\n",
    "    chunks = []\n",
    "    for tagged_text in tagged_texts:\n",
    "        tree = chunk_parser.parse(tagged_text)\n",
    "        tree = extract_chunks(tree)\n",
    "        tree = trees_to_tuples(tree)\n",
    "        chunks.append(tree)\n",
    "    chunks = [item for sublist in chunks for item in sublist]\n",
    "    return chunks\n",
    "\n",
    "def extract_chunks(tree):\n",
    "    chunks = []\n",
    "    \n",
    "    if isinstance(tree, nltk.Tree):\n",
    "        if tree.label() != 'S':  # Exclude sentence-level chunks if any\n",
    "            chunks.append(tree)\n",
    "        for subtree in tree:\n",
    "            chunks.extend(extract_chunks(subtree))\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "def trees_to_tuples(tree_list):\n",
    "    tuple_list = [tuple(leaf[0] for leaf in tree.leaves()) for tree in tree_list]\n",
    "    return tuple_list\n",
    "\n",
    "# Apply chunking and extraction to the 'tagged_sentences' column\n",
    "data['pattern_webb'] = data['lemmatized'].apply(lambda x: extract(x, pattern_webb))\n",
    "data['pattern_raharjana'] = data['lemmatized'].apply(lambda x: extract(x, pattern_raharjana))\n",
    "data['pattern_johann'] = data['lemmatized'].apply(lambda x: extract(x, pattern_johann))\n",
    "\n",
    "# Print the resulting DataFrame with chunked data\n",
    "data['pattern_webb']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hasile\n",
    "\n",
    "data = data[[\"data\", \"pattern_webb\", \"pattern_raharjana\", \"pattern_johann\"]]\n",
    "data.to_excel('data/keyword_extraction_eval_data.xlsx', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add Expected Result from Annotators Label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>pattern_webb</th>\n",
       "      <th>pattern_raharjana</th>\n",
       "      <th>pattern_johann</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The present invention relates to a method for ...</td>\n",
       "      <td>[(give, problem), (correspond, word), (inputti...</td>\n",
       "      <td>[(give, problem, opportunity, deeply), (corres...</td>\n",
       "      <td>[(generate, vocabulary, problem), (accord, pre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The present disclosure is directed to methods,...</td>\n",
       "      <td>[(direct, method), (prepare, food), (prepare, ...</td>\n",
       "      <td>[(direct, method), (prepare, food, dish), (pre...</td>\n",
       "      <td>[(direct, method), (include, robotic, kitchen)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>An anti-theft method for an oil tank truck bas...</td>\n",
       "      <td>[(base, machine), (learn, comprises), (follow,...</td>\n",
       "      <td>[(base, machine), (learn, comprises), (follow,...</td>\n",
       "      <td>[(base, machine), (learn, comprises), (follow,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The invention provides an artificial intellige...</td>\n",
       "      <td>[(categorize, event), (say, ai), (say, ai), (c...</td>\n",
       "      <td>[(categorize, event), (say, ai, system), (say,...</td>\n",
       "      <td>[(provide, artificial, intelligence), (categor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Systems and methods for using machine learning...</td>\n",
       "      <td>[(use, machine), (predict, risk), (pose, patie...</td>\n",
       "      <td>[(use, machine, learning, model), (predict, ri...</td>\n",
       "      <td>[(use, machine), (predict, risk), (pose, patie...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data  \\\n",
       "0  The present invention relates to a method for ...   \n",
       "1  The present disclosure is directed to methods,...   \n",
       "2  An anti-theft method for an oil tank truck bas...   \n",
       "3  The invention provides an artificial intellige...   \n",
       "4  Systems and methods for using machine learning...   \n",
       "\n",
       "                                        pattern_webb  \\\n",
       "0  [(give, problem), (correspond, word), (inputti...   \n",
       "1  [(direct, method), (prepare, food), (prepare, ...   \n",
       "2  [(base, machine), (learn, comprises), (follow,...   \n",
       "3  [(categorize, event), (say, ai), (say, ai), (c...   \n",
       "4  [(use, machine), (predict, risk), (pose, patie...   \n",
       "\n",
       "                                   pattern_raharjana  \\\n",
       "0  [(give, problem, opportunity, deeply), (corres...   \n",
       "1  [(direct, method), (prepare, food, dish), (pre...   \n",
       "2  [(base, machine), (learn, comprises), (follow,...   \n",
       "3  [(categorize, event), (say, ai, system), (say,...   \n",
       "4  [(use, machine, learning, model), (predict, ri...   \n",
       "\n",
       "                                      pattern_johann  \n",
       "0  [(generate, vocabulary, problem), (accord, pre...  \n",
       "1  [(direct, method), (include, robotic, kitchen)...  \n",
       "2  [(base, machine), (learn, comprises), (follow,...  \n",
       "3  [(provide, artificial, intelligence), (categor...  \n",
       "4  [(use, machine), (predict, risk), (pose, patie...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_excel('data/keyword_extraction_eval_data.xlsx')\n",
    "data['pattern_webb'] = data['pattern_webb'].apply(lambda x:list(eval(str(x))))\n",
    "data['pattern_raharjana'] = data['pattern_raharjana'].apply(lambda x:list(eval(str(x))))\n",
    "data['pattern_johann'] = data['pattern_johann'].apply(lambda x:list(eval(str(x))))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>keywords</th>\n",
       "      <th>Responden 1</th>\n",
       "      <th>Responden 2</th>\n",
       "      <th>Responden 3</th>\n",
       "      <th>Responden 4</th>\n",
       "      <th>Responden 5</th>\n",
       "      <th>labeling</th>\n",
       "      <th>not_labeling</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>automatically generating vocabulary problems</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>generate potential answers</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>automatically generating vocabulary problems</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>generate potential answers of high difficulty ...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>inputting target words</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                           keywords  Responden 1  \\\n",
       "0      0       automatically generating vocabulary problems          1.0   \n",
       "1      0                         generate potential answers          1.0   \n",
       "5      0       automatically generating vocabulary problems          1.0   \n",
       "7      0  generate potential answers of high difficulty ...          1.0   \n",
       "8      0                             inputting target words          0.0   \n",
       "\n",
       "   Responden 2  Responden 3  Responden 4  Responden 5  labeling  not_labeling  \n",
       "0          1.0          1.0          1.0          1.0         5             0  \n",
       "1          1.0          1.0          1.0          1.0         5             0  \n",
       "5          1.0          1.0          1.0          1.0         5             0  \n",
       "7          1.0          1.0          1.0          1.0         5             0  \n",
       "8          1.0          1.0          0.0          1.0         3             2  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "annotator_data = pd.read_excel('data/keyword_extraction_eval_count.xlsx')\n",
    "annotator_data = annotator_data[annotator_data['labeling'] >= 3]\n",
    "annotator_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>pattern_webb</th>\n",
       "      <th>pattern_raharjana</th>\n",
       "      <th>pattern_johann</th>\n",
       "      <th>expected_result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The present invention relates to a method for ...</td>\n",
       "      <td>[(give, problem), (correspond, word), (inputti...</td>\n",
       "      <td>[(give, problem, opportunity, deeply), (corres...</td>\n",
       "      <td>[(generate, vocabulary, problem), (accord, pre...</td>\n",
       "      <td>[(automatically, generating, vocabulary, probl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The present disclosure is directed to methods,...</td>\n",
       "      <td>[(direct, method), (prepare, food), (prepare, ...</td>\n",
       "      <td>[(direct, method), (prepare, food, dish), (pre...</td>\n",
       "      <td>[(direct, method), (include, robotic, kitchen)...</td>\n",
       "      <td>[(provide, different, ways, to, prepare, food,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>An anti-theft method for an oil tank truck bas...</td>\n",
       "      <td>[(base, machine), (learn, comprises), (follow,...</td>\n",
       "      <td>[(base, machine), (learn, comprises), (follow,...</td>\n",
       "      <td>[(base, machine), (learn, comprises), (follow,...</td>\n",
       "      <td>[(acquiring, scene, pictures), (predicting, wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The invention provides an artificial intellige...</td>\n",
       "      <td>[(categorize, event), (say, ai), (say, ai), (c...</td>\n",
       "      <td>[(categorize, event), (say, ai, system), (say,...</td>\n",
       "      <td>[(provide, artificial, intelligence), (categor...</td>\n",
       "      <td>[(categorizing, events), (categorizing, events...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Systems and methods for using machine learning...</td>\n",
       "      <td>[(use, machine), (predict, risk), (pose, patie...</td>\n",
       "      <td>[(use, machine, learning, model), (predict, ri...</td>\n",
       "      <td>[(use, machine), (predict, risk), (pose, patie...</td>\n",
       "      <td>[(predict, risks), (access, a, set, of, real-w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                data  \\\n",
       "0  The present invention relates to a method for ...   \n",
       "1  The present disclosure is directed to methods,...   \n",
       "2  An anti-theft method for an oil tank truck bas...   \n",
       "3  The invention provides an artificial intellige...   \n",
       "4  Systems and methods for using machine learning...   \n",
       "\n",
       "                                        pattern_webb  \\\n",
       "0  [(give, problem), (correspond, word), (inputti...   \n",
       "1  [(direct, method), (prepare, food), (prepare, ...   \n",
       "2  [(base, machine), (learn, comprises), (follow,...   \n",
       "3  [(categorize, event), (say, ai), (say, ai), (c...   \n",
       "4  [(use, machine), (predict, risk), (pose, patie...   \n",
       "\n",
       "                                   pattern_raharjana  \\\n",
       "0  [(give, problem, opportunity, deeply), (corres...   \n",
       "1  [(direct, method), (prepare, food, dish), (pre...   \n",
       "2  [(base, machine), (learn, comprises), (follow,...   \n",
       "3  [(categorize, event), (say, ai, system), (say,...   \n",
       "4  [(use, machine, learning, model), (predict, ri...   \n",
       "\n",
       "                                      pattern_johann  \\\n",
       "0  [(generate, vocabulary, problem), (accord, pre...   \n",
       "1  [(direct, method), (include, robotic, kitchen)...   \n",
       "2  [(base, machine), (learn, comprises), (follow,...   \n",
       "3  [(provide, artificial, intelligence), (categor...   \n",
       "4  [(use, machine), (predict, risk), (pose, patie...   \n",
       "\n",
       "                                     expected_result  \n",
       "0  [(automatically, generating, vocabulary, probl...  \n",
       "1  [(provide, different, ways, to, prepare, food,...  \n",
       "2  [(acquiring, scene, pictures), (predicting, wh...  \n",
       "3  [(categorizing, events), (categorizing, events...  \n",
       "4  [(predict, risks), (access, a, set, of, real-w...  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grouped = annotator_data.groupby('index')['keywords'].agg(list)\n",
    "grouped = grouped.apply(lambda x: [tuple(word.split()) for word in x])\n",
    "data['expected_result'] = grouped\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\oktav\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\oktav\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\oktav\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0     [(automatically, generate, vocabulary, problem...\n",
      "1     [(provide, different, way, to, prepare, food, ...\n",
      "2     [(acquire, scene, picture), (predict, whether)...\n",
      "3     [(categorize, event), (categorize, event), (ca...\n",
      "4     [(predict, risk), (access, a, set, of, realwor...\n",
      "5     [(collect, audio, and, video, data), (output, ...\n",
      "6     [(predict, and, provide, the, surface, roughne...\n",
      "7     [(recommend, content), (identify,), (transmit,...\n",
      "8     [(determine, to, which, social, group, a, pers...\n",
      "9     [(detect, and, position, a, move, object, unde...\n",
      "10    [(formulate, and, review), (coordinate,), (eva...\n",
      "11    [(directly, supervise, and, coordinate, the, a...\n",
      "12    [(advise, government, on, policy, matter), (ov...\n",
      "13    [(perform, clinical, test, on, specimen), (obt...\n",
      "14    [(study, and, ass), (develop, plan, and, solut...\n",
      "15    [(determine, the, exact, position), (prepare, ...\n",
      "16    [(conduct, research), (improve, or, develop, c...\n",
      "17    [(provide, basic, dental, care, service), (pro...\n",
      "18    [(analyst, assist, organization), (solve, orga...\n",
      "19    [(conduct, research), (monitor, data), (analys...\n",
      "20    [(fruit, quality, control, survey, system), (a...\n",
      "21    [(detect, a, paper, roll, packaging, defect), ...\n",
      "22    [(select, and, present, advertisement), (ident...\n",
      "23    [(control, a, plurality, of, robot), (receive,...\n",
      "24    [(predict, a, nonfraud, dispute), (receive, in...\n",
      "25    [(control, a, remote, surgical, robotic, instr...\n",
      "26    [(calculate, road, condition, cycle, number, o...\n",
      "27    [(position, a, catheter), (advance, and, retra...\n",
      "28    [(image, recognition), (determine, a, view, st...\n",
      "29    [(detects, a, human, body, fall), (fall, motio...\n",
      "30    [(stock, vend, machine), (collect, money), (st...\n",
      "31    [(provide, a, variety, of, service), (cleaning...\n",
      "32    [(accompany, individual, or, group), (describe...\n",
      "33    [(control, the, movement, of, railway, traffic...\n",
      "34    [(operate, machine), (pack,), (label, various,...\n",
      "35    [(provide, technical, assistance, to, user), (...\n",
      "36    [(prepare,), (weave,), (paint,), (decorate,), ...\n",
      "37    [(make, form, for, mould, concrete), (reinforc...\n",
      "38    [(gather, wild, fruit, medicinal, and, other, ...\n",
      "39    [(grow, and, harvest, field, or, tree, and, sh...\n",
      "Name: expected_result, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "\n",
    "# Download necessary NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Initialize Lemmatizer and stopwords\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Define preprocessing function\n",
    "def preprocess(text):\n",
    "    preprocessed_tuples = []\n",
    "    for tuple_ in text:\n",
    "        preprocessed_words = []\n",
    "        for word in tuple_:\n",
    "            # Lowercasing\n",
    "            word_lower = word.lower()\n",
    "            \n",
    "            # Removing punctuation\n",
    "            word_no_punct = ''.join([char for char in word_lower if char not in string.punctuation])\n",
    "            \n",
    "            # Tokenization\n",
    "            words = word_tokenize(word_no_punct)\n",
    "            \n",
    "            # Removing stopwords and Lemmatization\n",
    "            words_no_stopwords = []\n",
    "            for w in words:\n",
    "                # Get POS tag for the word\n",
    "                pos_tag = nltk.pos_tag([w])[0][1][0].lower()\n",
    "                # Lemmatize based on the POS tag\n",
    "                if pos_tag in ['a', 'n', 'r', 'v']:  # Adjective, noun, adverb, verb\n",
    "                    lemma = lemmatizer.lemmatize(w, pos=pos_tag)\n",
    "                else:\n",
    "                    lemma = w  # Keep the word unchanged if not recognized as one of the above POS tags\n",
    "                words_no_stopwords.append(lemma)\n",
    "            \n",
    "            preprocessed_words.extend(words_no_stopwords)\n",
    "        \n",
    "        preprocessed_tuples.append(tuple(preprocessed_words))\n",
    "    \n",
    "    return preprocessed_tuples\n",
    "\n",
    "# Apply preprocessing function to the column\n",
    "data['expected_result'] = data['expected_result'].apply(preprocess)\n",
    "\n",
    "print(data['expected_result'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hasile\n",
    "\n",
    "data.to_excel('data/keyword_extraction_eval_data.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
