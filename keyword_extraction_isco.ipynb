{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\oktav\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\oktav\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\oktav\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\oktav\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\oktav\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.chunk import RegexpParser\n",
    "from nltk import word_tokenize, pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "nltk.download('stopwords')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "string.punctuation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title EN</th>\n",
       "      <th>Definition</th>\n",
       "      <th>Tasks include</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Commissioned Armed Forces Officers</td>\n",
       "      <td>Commissioned armed forces officers provide lea...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Non-commissioned Armed Forces Officers</td>\n",
       "      <td>Non-commissioned armed forces officers enforce...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Armed Forces Occupations, Other Ranks</td>\n",
       "      <td>Armed forces occupations, other ranks include ...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Title EN  \\\n",
       "0      Commissioned Armed Forces Officers   \n",
       "1  Non-commissioned Armed Forces Officers   \n",
       "2   Armed Forces Occupations, Other Ranks   \n",
       "\n",
       "                                          Definition  Tasks include  \n",
       "0  Commissioned armed forces officers provide lea...            NaN  \n",
       "1  Non-commissioned armed forces officers enforce...            NaN  \n",
       "2  Armed forces occupations, other ranks include ...            NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data\n",
    "\n",
    "data = pd.read_excel('data/isco - Copy.xlsx')\n",
    "# data = data[data[\"ISCO 08 Code\"].apply(lambda x: len(str(x)) > 3)]\n",
    "data = data[[\"Title EN\", \"Definition\", \"Tasks include\"]]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title EN</th>\n",
       "      <th>Definition</th>\n",
       "      <th>Tasks include</th>\n",
       "      <th>definition_and_task</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Commissioned Armed Forces Officers</td>\n",
       "      <td>Commissioned armed forces officers provide lea...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Commissioned armed forces officers provide lea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Non-commissioned Armed Forces Officers</td>\n",
       "      <td>Non-commissioned armed forces officers enforce...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Non-commissioned armed forces officers enforce...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Armed Forces Occupations, Other Ranks</td>\n",
       "      <td>Armed forces occupations, other ranks include ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Armed forces occupations, other ranks include ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Title EN  \\\n",
       "0      Commissioned Armed Forces Officers   \n",
       "1  Non-commissioned Armed Forces Officers   \n",
       "2   Armed Forces Occupations, Other Ranks   \n",
       "\n",
       "                                          Definition  Tasks include  \\\n",
       "0  Commissioned armed forces officers provide lea...            NaN   \n",
       "1  Non-commissioned armed forces officers enforce...            NaN   \n",
       "2  Armed forces occupations, other ranks include ...            NaN   \n",
       "\n",
       "                                 definition_and_task  \n",
       "0  Commissioned armed forces officers provide lea...  \n",
       "1  Non-commissioned armed forces officers enforce...  \n",
       "2  Armed forces occupations, other ranks include ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# add . in the end of title\n",
    "def add_period(text):\n",
    "    if pd.notna(text):\n",
    "        return text + \". \"\n",
    "    else:\n",
    "        return text\n",
    "\n",
    "# Apply the function to the 'title' column\n",
    "data['Definition'] = data['Definition'].apply(add_period)\n",
    "\n",
    "# merge title and abstract column\n",
    "data['definition_and_task'] = data['Definition'] + data['Tasks include'].fillna('')\n",
    "\n",
    "# Print the updated DataFrame\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title EN               0\n",
      "Definition             0\n",
      "Tasks include          6\n",
      "definition_and_task    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check missing value\n",
    "\n",
    "print(data.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title EN</th>\n",
       "      <th>Definition</th>\n",
       "      <th>Tasks include</th>\n",
       "      <th>definition_and_task</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Legislators</td>\n",
       "      <td>Legislators determine, formulate, and direct p...</td>\n",
       "      <td>Tasks include -\\n(a)  presiding over or partic...</td>\n",
       "      <td>Legislators determine, formulate, and direct p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Senior Government Officials</td>\n",
       "      <td>Senior government officials advise governments...</td>\n",
       "      <td>Tasks include -\\n(a)  advising national, state...</td>\n",
       "      <td>Senior government officials advise governments...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Traditional Chiefs and Heads of Villages</td>\n",
       "      <td>Traditional chiefs and heads of villages perfo...</td>\n",
       "      <td>Tasks include -\\n(a)  allocating the use of co...</td>\n",
       "      <td>Traditional chiefs and heads of villages perfo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Officials of Special-interest Organizat...</td>\n",
       "      <td>Senior officials of special-interest organizat...</td>\n",
       "      <td>Tasks include -\\n(a)  determining and formulat...</td>\n",
       "      <td>Senior officials of special-interest organizat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Managing Directors and Chief Executives</td>\n",
       "      <td>Managing directors and chief executives formul...</td>\n",
       "      <td>Tasks include -\\n(a)  planning, directing and ...</td>\n",
       "      <td>Managing directors and chief executives formul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>604</th>\n",
       "      <td>Messengers, Package Deliverers and Luggage Por...</td>\n",
       "      <td>Messengers, package deliverers and luggage por...</td>\n",
       "      <td>Tasks include -\\n(a)  delivering messages, pac...</td>\n",
       "      <td>Messengers, package deliverers and luggage por...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>605</th>\n",
       "      <td>Odd Job Persons</td>\n",
       "      <td>Odd job persons clean, paint and maintain buil...</td>\n",
       "      <td>Tasks include -\\n(a)  repairing broken windows...</td>\n",
       "      <td>Odd job persons clean, paint and maintain buil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>606</th>\n",
       "      <td>Meter Readers and Vending-machine Collectors</td>\n",
       "      <td>Meter readers and vending-machine collectors s...</td>\n",
       "      <td>Tasks include -\\n(a)  filling storage areas of...</td>\n",
       "      <td>Meter readers and vending-machine collectors s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>607</th>\n",
       "      <td>Water and Firewood Collectors</td>\n",
       "      <td>Water and firewood collectors collect water an...</td>\n",
       "      <td>Tasks include -\\n(a)  cutting and collecting w...</td>\n",
       "      <td>Water and firewood collectors collect water an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>608</th>\n",
       "      <td>Elementary Workers Not Elsewhere Classified</td>\n",
       "      <td>This unit group covers elementary workers not ...</td>\n",
       "      <td>In such cases tasks would include -\\n(a)  sell...</td>\n",
       "      <td>This unit group covers elementary workers not ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>433 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Title EN  \\\n",
       "3                                          Legislators   \n",
       "4                          Senior Government Officials   \n",
       "5             Traditional Chiefs and Heads of Villages   \n",
       "6    Senior Officials of Special-interest Organizat...   \n",
       "8              Managing Directors and Chief Executives   \n",
       "..                                                 ...   \n",
       "604  Messengers, Package Deliverers and Luggage Por...   \n",
       "605                                    Odd Job Persons   \n",
       "606       Meter Readers and Vending-machine Collectors   \n",
       "607                      Water and Firewood Collectors   \n",
       "608        Elementary Workers Not Elsewhere Classified   \n",
       "\n",
       "                                            Definition  \\\n",
       "3    Legislators determine, formulate, and direct p...   \n",
       "4    Senior government officials advise governments...   \n",
       "5    Traditional chiefs and heads of villages perfo...   \n",
       "6    Senior officials of special-interest organizat...   \n",
       "8    Managing directors and chief executives formul...   \n",
       "..                                                 ...   \n",
       "604  Messengers, package deliverers and luggage por...   \n",
       "605  Odd job persons clean, paint and maintain buil...   \n",
       "606  Meter readers and vending-machine collectors s...   \n",
       "607  Water and firewood collectors collect water an...   \n",
       "608  This unit group covers elementary workers not ...   \n",
       "\n",
       "                                         Tasks include  \\\n",
       "3    Tasks include -\\n(a)  presiding over or partic...   \n",
       "4    Tasks include -\\n(a)  advising national, state...   \n",
       "5    Tasks include -\\n(a)  allocating the use of co...   \n",
       "6    Tasks include -\\n(a)  determining and formulat...   \n",
       "8    Tasks include -\\n(a)  planning, directing and ...   \n",
       "..                                                 ...   \n",
       "604  Tasks include -\\n(a)  delivering messages, pac...   \n",
       "605  Tasks include -\\n(a)  repairing broken windows...   \n",
       "606  Tasks include -\\n(a)  filling storage areas of...   \n",
       "607  Tasks include -\\n(a)  cutting and collecting w...   \n",
       "608  In such cases tasks would include -\\n(a)  sell...   \n",
       "\n",
       "                                   definition_and_task  \n",
       "3    Legislators determine, formulate, and direct p...  \n",
       "4    Senior government officials advise governments...  \n",
       "5    Traditional chiefs and heads of villages perfo...  \n",
       "6    Senior officials of special-interest organizat...  \n",
       "8    Managing directors and chief executives formul...  \n",
       "..                                                 ...  \n",
       "604  Messengers, package deliverers and luggage por...  \n",
       "605  Odd job persons clean, paint and maintain buil...  \n",
       "606  Meter readers and vending-machine collectors s...  \n",
       "607  Water and firewood collectors collect water an...  \n",
       "608  This unit group covers elementary workers not ...  \n",
       "\n",
       "[433 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # remove missing value (tidak perlu karena kolom title and abstract tidak memiliki missing value)\n",
    "\n",
    "# data.dropna(inplace=True)\n",
    "# data.head()\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    commissioned armed forces officers provide lea...\n",
       "1    non-commissioned armed forces officers enforce...\n",
       "2    armed forces occupations, other ranks include ...\n",
       "Name: lowered, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lowering text\n",
    "data['lowered']= data['definition_and_task'].apply(lambda x: x.lower())\n",
    "\n",
    "# Print the updated DataFrame\n",
    "data['lowered'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to tokenize each sentence, tokenize each word from sentence, then remove punctuation and sopword\n",
    "def tokenize_and_remove_punctuation(text):\n",
    "    # Define stopword\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "\n",
    "    # Tokenize each sentence\n",
    "    sentences = re.split(r'(?<=[.!?,;])\\s+', text)\n",
    "    \n",
    "    # Tokenize each word in each sentence, remove punctuation, and remove stopword\n",
    "    tokenized_sentences = []\n",
    "    for sentence in sentences:\n",
    "        tokens = word_tokenize(sentence)\n",
    "        # Remove punctuation\n",
    "        tokens = [token for token in tokens if token not in string.punctuation]\n",
    "        # Remove stopword\n",
    "        tokens = [token for token in tokens if token not in stop_words]\n",
    "        tokenized_sentences.append(tokens)\n",
    "    return tokenized_sentences\n",
    "\n",
    "# Tokenize each sentence and remove punctuation & stopword\n",
    "data['tokenized'] = data['lowered'].apply(tokenize_and_remove_punctuation)\n",
    "\n",
    "# Print the updated DataFrame\n",
    "# print(data['tokenized'][3])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform POS tagging on each token\n",
    "def pos_tag_tokens(tokenized_sentences):\n",
    "    pos_tagged_sentences = []\n",
    "    for sentence_tokens in tokenized_sentences:\n",
    "        pos_tags = pos_tag(sentence_tokens)\n",
    "        pos_tagged_sentences.append(pos_tags)\n",
    "    return pos_tagged_sentences\n",
    "\n",
    "# Perform POS tagging on tokenized sentences\n",
    "data['pos_tagged'] = data['tokenized'].apply(pos_tag_tokens)\n",
    "\n",
    "# Print the updated DataFrame\n",
    "# print(data['pos_tagged'][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to lemmatize tokens\n",
    "def lemmatize_tokens(pos_tagged_sentences):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_sentences = []\n",
    "    for sentence_tags in pos_tagged_sentences:\n",
    "        lemmatized_tokens = [(lemmatizer.lemmatize(token, pos=get_wordnet_pos(pos_tag)), pos_tag) for token, pos_tag in sentence_tags]\n",
    "        lemmatized_sentences.append(lemmatized_tokens)\n",
    "    return lemmatized_sentences\n",
    "\n",
    "# Function to map POS tags to WordNet POS tags\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return nltk.corpus.wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return nltk.corpus.wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return nltk.corpus.wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return nltk.corpus.wordnet.ADV\n",
    "    else:\n",
    "        return nltk.corpus.wordnet.NOUN  # Default to noun if POS tag not recognized\n",
    "\n",
    "# Lemmatize the tokens in 'pos_tagged_sentences' column\n",
    "data['lemmatized'] = data['pos_tagged'].apply(lemmatize_tokens)\n",
    "\n",
    "# Print the updated DataFrame\n",
    "# print(data['lemmatized'][3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS Chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    [(provide, leadership), (arm, force), (perform...\n",
       "1    [(arm, force), (arm, force), (perform, variety...\n",
       "2     [(arm, force), (arm, force), (perform, variety)]\n",
       "Name: pattern_webb, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# POS chunk new pattern (Pak Indra)\n",
    "\n",
    "# define pattern\n",
    "pattern_raharjana = r'''Chunk: {<VB\\w*>+<.|IN|CC|PRP\\w*>*<DT>*<NN\\w*|RB>+}'''\n",
    "pattern_webb = r'''Chunk: {<VB\\w*><NN\\w*>}'''\n",
    "pattern_johann = r'''Chunk: {<VB\\w*><NN\\w*>|<VB\\w*><PRP\\w*><NN\\w*>|<VB\\w*><NN\\w*><NN\\w*>|<VB\\w*><JJ\\w*><NN\\w*>|<VB\\w*><DT><NN\\w*>|<VB\\w*><NN\\w*><IN><NN\\w*>|<VB\\w*><IN><JJ\\w*><NN\\w*>|<VB\\w*><PRP\\w*><JJ\\w*><NN\\w*>}'''\n",
    "\n",
    "def extract(tagged_texts, pattern):\n",
    "    chunk_parser = RegexpParser(pattern)\n",
    "    chunks = []\n",
    "    for tagged_text in tagged_texts:\n",
    "        tree = chunk_parser.parse(tagged_text)\n",
    "        tree = extract_chunks(tree)\n",
    "        tree = trees_to_tuples(tree)\n",
    "        chunks.append(tree)\n",
    "    chunks = [item for sublist in chunks for item in sublist]\n",
    "    return chunks\n",
    "\n",
    "def extract_chunks(tree):\n",
    "    chunks = []\n",
    "    \n",
    "    if isinstance(tree, nltk.Tree):\n",
    "        if tree.label() != 'S':  # Exclude sentence-level chunks if any\n",
    "            chunks.append(tree)\n",
    "        for subtree in tree:\n",
    "            chunks.extend(extract_chunks(subtree))\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "def trees_to_tuples(tree_list):\n",
    "    tuple_list = [tuple(leaf[0] for leaf in tree.leaves()) for tree in tree_list]\n",
    "    return tuple_list\n",
    "\n",
    "# Apply chunking and extraction to the 'tagged_sentences' column\n",
    "data['pattern_webb'] = data['lemmatized'].apply(lambda x: extract(x, pattern_webb))\n",
    "data['pattern_raharjana'] = data['lemmatized'].apply(lambda x: extract(x, pattern_raharjana))\n",
    "data['pattern_johann'] = data['lemmatized'].apply(lambda x: extract(x, pattern_johann))\n",
    "\n",
    "# Print the resulting DataFrame with chunked data\n",
    "data['pattern_webb']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hasile\n",
    "\n",
    "# patent_task = data[[\"Title EN\", \"definition_and_task\", \"pattern_webb\", \"pattern_raharjana\", \"pattern_johann\"]]\n",
    "data.to_excel('data/keyword_extraction_isco - Copy.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
