{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_and_abstract</th>\n",
       "      <th>chunked_verb_noun</th>\n",
       "      <th>chunked_new_pattern</th>\n",
       "      <th>expected_result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fire detection system based on artificial inte...</td>\n",
       "      <td>[(detect, fire), (generate, video), (analyze, ...</td>\n",
       "      <td>[(base, on, ai), (base, on, ai), (detect, fire...</td>\n",
       "      <td>[(detect, fire), (generate, video, image), (ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the present disclosure relates to a fire detec...</td>\n",
       "      <td>[(detect, fire), (generate, video), (analyze, ...</td>\n",
       "      <td>[(base, on, ai), (base, on, ai), (detect, fire...</td>\n",
       "      <td>[(detect, fire), (generate, video, image), (ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>embedding artificial intelligence for balancin...</td>\n",
       "      <td>[(balance, access), (process, load), (enable, ...</td>\n",
       "      <td>[(balance, access, point, process, load), (ena...</td>\n",
       "      <td>[(balance, access, point), (determine, rssi, v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>responsive to a cpu load of a specific access ...</td>\n",
       "      <td>[(threshold, value), (determine, rssi)]</td>\n",
       "      <td>[(threshold, value), (determine, rssi, value),...</td>\n",
       "      <td>[(determine, rssi, value)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>optimization techniques for artificial intelli...</td>\n",
       "      <td>[(receive, annotation), (determine, document),...</td>\n",
       "      <td>[(comprise, select, from, a, pool), (be, annot...</td>\n",
       "      <td>[(generate, a, natural, language, model), (gen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  title_and_abstract  \\\n",
       "0  fire detection system based on artificial inte...   \n",
       "1  the present disclosure relates to a fire detec...   \n",
       "2  embedding artificial intelligence for balancin...   \n",
       "3  responsive to a cpu load of a specific access ...   \n",
       "4  optimization techniques for artificial intelli...   \n",
       "\n",
       "                                   chunked_verb_noun  \\\n",
       "0  [(detect, fire), (generate, video), (analyze, ...   \n",
       "1  [(detect, fire), (generate, video), (analyze, ...   \n",
       "2  [(balance, access), (process, load), (enable, ...   \n",
       "3            [(threshold, value), (determine, rssi)]   \n",
       "4  [(receive, annotation), (determine, document),...   \n",
       "\n",
       "                                 chunked_new_pattern  \\\n",
       "0  [(base, on, ai), (base, on, ai), (detect, fire...   \n",
       "1  [(base, on, ai), (base, on, ai), (detect, fire...   \n",
       "2  [(balance, access, point, process, load), (ena...   \n",
       "3  [(threshold, value), (determine, rssi, value),...   \n",
       "4  [(comprise, select, from, a, pool), (be, annot...   \n",
       "\n",
       "                                     expected_result  \n",
       "0  [(detect, fire), (generate, video, image), (ex...  \n",
       "1  [(detect, fire), (generate, video, image), (ex...  \n",
       "2  [(balance, access, point), (determine, rssi, v...  \n",
       "3                         [(determine, rssi, value)]  \n",
       "4  [(generate, a, natural, language, model), (gen...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data\n",
    "\n",
    "data = pd.read_excel('data/accuration_test.xlsx')\n",
    "data['chunked_verb_noun'] = data['chunked_verb_noun'].apply(lambda x:list(eval(str(x))))\n",
    "data['chunked_new_pattern'] = data['chunked_new_pattern'].apply(lambda x:list(eval(str(x))))\n",
    "data['expected_result'] = data['expected_result'].apply(lambda x:list(eval(str(x))))\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0           [(detect, fire), (generate, video, image)]\n",
       "1           [(detect, fire), (generate, video, image)]\n",
       "2    [(balance, access, point), (determine, rssi, v...\n",
       "3    [(determine, rssi, value), (determine, rssi, v...\n",
       "4    [(receive, annotation), (select, from, a, pool...\n",
       "5    [(receive, annotation), (select, from, a, pool...\n",
       "6    [(create, a, secure, distributed, data, valida...\n",
       "7    [(validate, paper, forms), (select, a, first, ...\n",
       "8    [(track, player, attributes), (personalize, di...\n",
       "9    [(optimize, planning), (select, an, optimal, m...\n",
       "Name: true_verb_noun, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the right predicted chunk from verb-noun pattern\n",
    "\n",
    "def find_true_verb_noun(index):\n",
    "    common_tuples = []\n",
    "    for tuple1 in data['chunked_verb_noun'][index]:\n",
    "        for tuple2 in data['expected_result'][index]:\n",
    "            if any(word in tuple2 for word in tuple1):\n",
    "                common_tuples.append(tuple2)\n",
    "                break\n",
    "    return common_tuples\n",
    "\n",
    "data['true_verb_noun'] = data.apply(lambda row: find_true_verb_noun(row.name), axis=1)\n",
    "data['true_verb_noun']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [(detect, fire), (generate, video, image), (ex...\n",
       "1    [(detect, fire), (generate, video, image), (ex...\n",
       "2    [(balance, access, point), (determine, rssi, v...\n",
       "3    [(determine, rssi, value), (determine, rssi, v...\n",
       "4    [(generate, a, natural, language, model), (rec...\n",
       "5    [(generate, a, natural, language, model), (rec...\n",
       "6    [(create, a, secure, distributed, data, valida...\n",
       "7    [(validate, paper, forms), (determine, first, ...\n",
       "8    [(animate, a, virtual, player), (track, game, ...\n",
       "9    [(optimize, planning), (select, an, optimal, m...\n",
       "Name: true_new_pattern, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the right predicted chunk from new pattern (pattern Pak Indra)\n",
    "\n",
    "def find_true_new_pattern(index):\n",
    "    common_tuples = []\n",
    "    for tuple1 in data['chunked_new_pattern'][index]:\n",
    "        for tuple2 in data['expected_result'][index]:\n",
    "            if any(word in tuple2 for word in tuple1):\n",
    "                common_tuples.append(tuple2)\n",
    "                break\n",
    "    return common_tuples\n",
    "\n",
    "data['true_new_pattern'] = data.apply(lambda row: find_true_new_pattern(row.name), axis=1)\n",
    "data['true_new_pattern']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                       [(analyze, part)]\n",
       "1                       [(analyze, part)]\n",
       "2    [(process, load), (enable, network)]\n",
       "3                                      []\n",
       "4                                      []\n",
       "5                                      []\n",
       "6                                      []\n",
       "7                                      []\n",
       "8                                      []\n",
       "9                 [(include, management)]\n",
       "Name: false_verb_noun, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the false predicted chunk from verb-noun pattern\n",
    "\n",
    "def find_false_verb_noun(index):\n",
    "    disjoint_tuples = []\n",
    "    for tuple1 in data['chunked_verb_noun'][index]:\n",
    "        found_common = False\n",
    "        for tuple2 in data['expected_result'][index]:\n",
    "            if any(word in tuple2 for word in tuple1):\n",
    "                found_common = True\n",
    "                break\n",
    "        if not found_common:\n",
    "            disjoint_tuples.append(tuple1)\n",
    "    return disjoint_tuples\n",
    "\n",
    "data['false_verb_noun'] = data.apply(lambda row: find_false_verb_noun(row.name), axis=1)\n",
    "data['false_verb_noun']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [(base, on, ai), (base, on, ai), (analyze, part)]\n",
       "1    [(base, on, ai), (base, on, ai), (analyze, part)]\n",
       "2    [(enable, network), (be, then, continue, for, ...\n",
       "3    [(be, then, continue, for, the, wireless, stat...\n",
       "4                                                   []\n",
       "5                                                   []\n",
       "6                                                   []\n",
       "7                                                   []\n",
       "8    [(portray, base, on, circumstance), (support, ...\n",
       "9    [(include, management, information), (be, for,...\n",
       "Name: false_new_pattern, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the false predicted chunk from new pattern (pattern Pak Indra)\n",
    "\n",
    "def find_false_new_pattern(index):\n",
    "    disjoint_tuples = []\n",
    "    for tuple1 in data['chunked_new_pattern'][index]:\n",
    "        found_common = False\n",
    "        for tuple2 in data['expected_result'][index]:\n",
    "            if any(word in tuple2 for word in tuple1):\n",
    "                found_common = True\n",
    "                break\n",
    "        if not found_common:\n",
    "            disjoint_tuples.append(tuple1)\n",
    "    return disjoint_tuples\n",
    "\n",
    "data['false_new_pattern'] = data.apply(lambda row: find_false_new_pattern(row.name), axis=1)\n",
    "data['false_new_pattern']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [(extract, a, motion, object), (generate, a, f...\n",
       "1    [(extract, a, motion, object), (generate, a, f...\n",
       "2                                                   []\n",
       "3                                                   []\n",
       "4    [(generate, a, natural, language, model), (gen...\n",
       "5    [(generate, a, natural, language, model), (gen...\n",
       "6    [(receive, paper, form, data), (determine, fir...\n",
       "7    [(receive, paper, form, data), (determine, fir...\n",
       "8    [(track, game, states), (select, speech), (det...\n",
       "9    [(execute, an, order), (provide, an, optimal, ...\n",
       "Name: unpredicted_verb_noun, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the unpredicted chunk from verb-noun pattern\n",
    "\n",
    "def find_unpredicted_verb_noun(index):\n",
    "    result = [i for i in data['expected_result'][index] if i not in data['true_verb_noun'][index]]\n",
    "    return result\n",
    "\n",
    "data['unpredicted_verb_noun'] = data.apply(lambda row: find_unpredicted_verb_noun(row.name), axis=1)\n",
    "data['unpredicted_verb_noun']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [(generate, a, first, background, removal, ima...\n",
       "1    [(generate, a, first, background, removal, ima...\n",
       "2                                                   []\n",
       "3                                                   []\n",
       "4    [(train, a, natural, language, model), (use, t...\n",
       "5    [(train, a, natural, language, model), (use, t...\n",
       "6    [(receive, paper, form, data), (determine, sec...\n",
       "7    [(determine, second, metadata), (determine, re...\n",
       "8    [(select, speech), (determine, emotions), (pro...\n",
       "9    [(provide, an, optimal, manufacturing, location)]\n",
       "Name: unpredicted_new_pattern, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the unpredicted chunk from new pattern (pattern Pak Indra)\n",
    "\n",
    "def find_unpredicted_new_pattern(index):\n",
    "    result = [i for i in data['expected_result'][index] if i not in data['true_new_pattern'][index]]\n",
    "    return result\n",
    "\n",
    "data['unpredicted_new_pattern'] = data.apply(lambda row: find_unpredicted_new_pattern(row.name), axis=1)\n",
    "data['unpredicted_new_pattern']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hasil chunk verb noun pattern\n",
      "\n",
      "True positive =  28\n",
      "False positive =  5\n",
      "False negative =  50\n",
      "\n",
      "Precision =  0.8484848484848485\n",
      "Recall =  0.358974358974359\n",
      "F1 score =  0.5045045045045045\n"
     ]
    }
   ],
   "source": [
    "# count percentage of verb noun pattern accuracy\n",
    "\n",
    "tp_verb_noun = data['true_verb_noun'].apply(len).sum()\n",
    "fp_verb_noun = data['false_verb_noun'].apply(len).sum()\n",
    "fn_verb_noun = data['unpredicted_verb_noun'].apply(len).sum()\n",
    "precision_verb_noun = tp_verb_noun / (tp_verb_noun + fp_verb_noun)\n",
    "recall_verb_noun = tp_verb_noun / (tp_verb_noun + fn_verb_noun)\n",
    "f1score_verb_noun = 2 * (precision_verb_noun * recall_verb_noun) / (precision_verb_noun + recall_verb_noun)\n",
    "\n",
    "print(\"Hasil chunk verb noun pattern\\n\")\n",
    "print(\"True positive = \", tp_verb_noun)\n",
    "print(\"False positive = \", fp_verb_noun)\n",
    "print(\"False negative = \", fn_verb_noun)\n",
    "print(\"\\nPrecision = \", precision_verb_noun)\n",
    "print(\"Recall = \", recall_verb_noun)\n",
    "print(\"F1 score = \", f1score_verb_noun)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hasil chunk new pattern (pattern Pak Indra)\n",
      "\n",
      "True positive =  56\n",
      "False positive =  14\n",
      "False negative =  36\n",
      "\n",
      "Precision =  0.8\n",
      "Recall =  0.6086956521739131\n",
      "F1 score =  0.6913580246913581\n"
     ]
    }
   ],
   "source": [
    "# count percentage of new pattern accuracy\n",
    "\n",
    "tp_new_pattern = data['true_new_pattern'].apply(len).sum()\n",
    "fp_new_pattern = data['false_new_pattern'].apply(len).sum()\n",
    "fn_new_pattern = data['unpredicted_new_pattern'].apply(len).sum()\n",
    "precision_new_pattern = tp_new_pattern / (tp_new_pattern + fp_new_pattern)\n",
    "recall_new_pattern = tp_new_pattern / (tp_new_pattern + fn_new_pattern)\n",
    "f1score_new_pattern = 2 * (precision_new_pattern * recall_new_pattern) / (precision_new_pattern + recall_new_pattern)\n",
    "\n",
    "print(\"Hasil chunk new pattern (pattern Pak Indra)\\n\")\n",
    "print(\"True positive = \", tp_new_pattern)\n",
    "print(\"False positive = \", fp_new_pattern)\n",
    "print(\"False negative = \", fn_new_pattern)\n",
    "print(\"\\nPrecision = \", precision_new_pattern)\n",
    "print(\"Recall = \", recall_new_pattern)\n",
    "print(\"F1 score = \", f1score_new_pattern)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hasile\n",
    "\n",
    "data.to_excel('export_result/test.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
