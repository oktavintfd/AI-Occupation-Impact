{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title_and_abstract</th>\n",
       "      <th>chunked_verb_noun</th>\n",
       "      <th>chunked_new_pattern</th>\n",
       "      <th>expected_result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fire detection system based on artificial inte...</td>\n",
       "      <td>[(detect, fire), (generate, video), (analyze, ...</td>\n",
       "      <td>[(base, on, ai), (base, on, ai), (detect, fire...</td>\n",
       "      <td>[(detect, fire), (generate, video, image), (ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>the present disclosure relates to a fire detec...</td>\n",
       "      <td>[(detect, fire), (generate, video), (analyze, ...</td>\n",
       "      <td>[(base, on, ai), (base, on, ai), (detect, fire...</td>\n",
       "      <td>[(detect, fire), (generate, video, image), (ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>embedding artificial intelligence for balancin...</td>\n",
       "      <td>[(balance, access), (process, load), (enable, ...</td>\n",
       "      <td>[(balance, access, point, process, load), (ena...</td>\n",
       "      <td>[(balance, access, point), (determine, rssi, v...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>responsive to a cpu load of a specific access ...</td>\n",
       "      <td>[(threshold, value), (determine, rssi)]</td>\n",
       "      <td>[(threshold, value), (determine, rssi, value),...</td>\n",
       "      <td>[(determine, rssi, value)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>optimization techniques for artificial intelli...</td>\n",
       "      <td>[(receive, annotation), (determine, document),...</td>\n",
       "      <td>[(comprise, select, from, a, pool), (be, annot...</td>\n",
       "      <td>[(generate, a, natural, language, model), (gen...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  title_and_abstract  \\\n",
       "0  fire detection system based on artificial inte...   \n",
       "1  the present disclosure relates to a fire detec...   \n",
       "2  embedding artificial intelligence for balancin...   \n",
       "3  responsive to a cpu load of a specific access ...   \n",
       "4  optimization techniques for artificial intelli...   \n",
       "\n",
       "                                   chunked_verb_noun  \\\n",
       "0  [(detect, fire), (generate, video), (analyze, ...   \n",
       "1  [(detect, fire), (generate, video), (analyze, ...   \n",
       "2  [(balance, access), (process, load), (enable, ...   \n",
       "3            [(threshold, value), (determine, rssi)]   \n",
       "4  [(receive, annotation), (determine, document),...   \n",
       "\n",
       "                                 chunked_new_pattern  \\\n",
       "0  [(base, on, ai), (base, on, ai), (detect, fire...   \n",
       "1  [(base, on, ai), (base, on, ai), (detect, fire...   \n",
       "2  [(balance, access, point, process, load), (ena...   \n",
       "3  [(threshold, value), (determine, rssi, value),...   \n",
       "4  [(comprise, select, from, a, pool), (be, annot...   \n",
       "\n",
       "                                     expected_result  \n",
       "0  [(detect, fire), (generate, video, image), (ex...  \n",
       "1  [(detect, fire), (generate, video, image), (ex...  \n",
       "2  [(balance, access, point), (determine, rssi, v...  \n",
       "3                         [(determine, rssi, value)]  \n",
       "4  [(generate, a, natural, language, model), (gen...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data\n",
    "\n",
    "data = pd.read_excel('data/accuration_test.xlsx')\n",
    "data['chunked_verb_noun'] = data['chunked_verb_noun'].apply(lambda x:list(eval(str(x))))\n",
    "data['chunked_new_pattern'] = data['chunked_new_pattern'].apply(lambda x:list(eval(str(x))))\n",
    "data['expected_result'] = data['expected_result'].apply(lambda x:list(eval(str(x))))\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                     [(detect, fire)]\n",
       "1                                     [(detect, fire)]\n",
       "2                                                   []\n",
       "3                                                   []\n",
       "4    [(receive, annotation), (determine, document),...\n",
       "5    [(receive, annotation), (determine, document),...\n",
       "6                                                   []\n",
       "7                                                   []\n",
       "8           [(personalize, dialogue), (perform, card)]\n",
       "9                               [(optimize, planning)]\n",
       "Name: true_verb_noun, dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the right predicted chunk from verb-noun pattern\n",
    "\n",
    "def find_true_verb_noun(index, data):\n",
    "    result = [i for i in data['chunked_verb_noun'][index] if i in data['expected_result'][index]]\n",
    "    return result\n",
    "\n",
    "data['true_verb_noun'] = data.apply(lambda row: find_true_verb_noun(row.name, data), axis=1)\n",
    "data['true_verb_noun']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       [(detect, fire), (extract, a, motion, object)]\n",
       "1       [(detect, fire), (extract, a, motion, object)]\n",
       "2                           [(determine, rssi, value)]\n",
       "3                           [(determine, rssi, value)]\n",
       "4       [(determine, document), (receive, annotation)]\n",
       "5       [(determine, document), (receive, annotation)]\n",
       "6    [(validate, paper, form), (receive, a, validat...\n",
       "7    [(receive, a, validation, status), (generate, ...\n",
       "8           [(personalize, dialogue), (perform, card)]\n",
       "9         [(optimize, planning), (execute, an, order)]\n",
       "Name: true_new_pattern, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the right predicted chunk from new pattern (pattern Pak Indra)\n",
    "\n",
    "def find_true_new_pattern(index, data):\n",
    "    result = [i for i in data['chunked_new_pattern'][index] if i in data['expected_result'][index]]\n",
    "    return result\n",
    "\n",
    "data['true_new_pattern'] = data.apply(lambda row: find_true_new_pattern(row.name, data), axis=1)\n",
    "data['true_new_pattern']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                 [(generate, video), (analyze, part)]\n",
       "1                 [(generate, video), (analyze, part)]\n",
       "2    [(balance, access), (process, load), (enable, ...\n",
       "3              [(threshold, value), (determine, rssi)]\n",
       "4                               [(comprise, document)]\n",
       "5                               [(comprise, document)]\n",
       "6    [(distribute, data), (distribute, storage), (v...\n",
       "7           [(validate, paper), (distribute, storage)]\n",
       "8                                    [(track, system)]\n",
       "9      [(include, management), (select, optimization)]\n",
       "Name: false_verb_noun, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the false predicted chunk from verb-noun pattern\n",
    "\n",
    "def find_false_verb_noun(index, data):\n",
    "    result = [i for i in data['chunked_verb_noun'][index] if i not in data['true_verb_noun'][index]]\n",
    "    return result\n",
    "\n",
    "data['false_verb_noun'] = data.apply(lambda row: find_false_verb_noun(row.name, data), axis=1)\n",
    "data['false_verb_noun']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [(base, on, ai), (base, on, ai), (include, a, ...\n",
       "1    [(base, on, ai), (base, on, ai), (include, a, ...\n",
       "2    [(balance, access, point, process, load), (ena...\n",
       "3    [(threshold, value), (be, then, continue, for,...\n",
       "4    [(comprise, select, from, a, pool), (be, annot...\n",
       "5    [(comprise, select, from, a, pool), (be, annot...\n",
       "6    [(create, a, secure, distribute, data, validat...\n",
       "7    [(validate, paper, form), (have, first), (dete...\n",
       "8    [(be, embody, a, a, video, hologram), (base, o...\n",
       "9    [(be, receive, include, the, order), (include,...\n",
       "Name: false_new_pattern, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the false predicted chunk from new pattern (pattern Pak Indra)\n",
    "\n",
    "def find_false_new_pattern(index, data):\n",
    "    result = [i for i in data['chunked_new_pattern'][index] if i not in data['true_new_pattern'][index]]\n",
    "    return result\n",
    "\n",
    "data['false_new_pattern'] = data.apply(lambda row: find_false_new_pattern(row.name, data), axis=1)\n",
    "data['false_new_pattern']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [(generate, video, image), (extract, a, motion...\n",
       "1    [(generate, video, image), (extract, a, motion...\n",
       "2    [(balance, access, point), (determine, rssi, v...\n",
       "3                           [(determine, rssi, value)]\n",
       "4    [(generate, a, natural, language, model), (gen...\n",
       "5    [(generate, a, natural, language, model), (gen...\n",
       "6    [(create, a, secure, distributed, data, valida...\n",
       "7    [(validate, paper, forms), (receive, paper, fo...\n",
       "8    [(track, player, attributes), (track, game, st...\n",
       "9    [(select, an, optimal, manufacturing, location...\n",
       "Name: unpredicted_verb_noun, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the unpredicted chunk from verb-noun pattern\n",
    "\n",
    "def find_unpredicted_verb_noun(index, data):\n",
    "    result = [i for i in data['expected_result'][index] if i not in data['true_verb_noun'][index]]\n",
    "    return result\n",
    "\n",
    "data['unpredicted_verb_noun'] = data.apply(lambda row: find_unpredicted_verb_noun(row.name, data), axis=1)\n",
    "data['unpredicted_verb_noun']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [(generate, video, image), (generate, a, first...\n",
       "1    [(generate, video, image), (generate, a, first...\n",
       "2                           [(balance, access, point)]\n",
       "3                                                   []\n",
       "4    [(generate, a, natural, language, model), (gen...\n",
       "5    [(generate, a, natural, language, model), (gen...\n",
       "6    [(create, a, secure, distributed, data, valida...\n",
       "7    [(validate, paper, forms), (receive, paper, fo...\n",
       "8    [(track, player, attributes), (track, game, st...\n",
       "9    [(select, an, optimal, manufacturing, location...\n",
       "Name: unpredicted_new_pattern, dtype: object"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the unpredicted chunk from new pattern (pattern Pak Indra)\n",
    "\n",
    "def find_unpredicted_new_pattern(index, data):\n",
    "    result = [i for i in data['expected_result'][index] if i not in data['true_new_pattern'][index]]\n",
    "    return result\n",
    "\n",
    "data['unpredicted_new_pattern'] = data.apply(lambda row: find_unpredicted_new_pattern(row.name, data), axis=1)\n",
    "data['unpredicted_new_pattern']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hasil chunk verb noun pattern\n",
      "\n",
      "True positive =  11\n",
      "False positive =  22\n",
      "False negative =  62\n",
      "\n",
      "Precision =  0.3333333333333333\n",
      "Recall =  0.1506849315068493\n",
      "F1 score =  0.20754716981132076\n"
     ]
    }
   ],
   "source": [
    "# count percentage of verb noun pattern accuracy\n",
    "\n",
    "tp_verb_noun = data['true_verb_noun'].apply(len).sum()\n",
    "fp_verb_noun = data['false_verb_noun'].apply(len).sum()\n",
    "fn_verb_noun = data['unpredicted_verb_noun'].apply(len).sum()\n",
    "precision_verb_noun = tp_verb_noun / (tp_verb_noun + fp_verb_noun)\n",
    "recall_verb_noun = tp_verb_noun / (tp_verb_noun + fn_verb_noun)\n",
    "f1score_verb_noun = 2 * (precision_verb_noun * recall_verb_noun) / (precision_verb_noun + recall_verb_noun)\n",
    "\n",
    "print(\"Hasil chunk verb noun pattern\\n\")\n",
    "print(\"True positive = \", tp_verb_noun)\n",
    "print(\"False positive = \", fp_verb_noun)\n",
    "print(\"False negative = \", fn_verb_noun)\n",
    "print(\"\\nPrecision = \", precision_verb_noun)\n",
    "print(\"Recall = \", recall_verb_noun)\n",
    "print(\"F1 score = \", f1score_verb_noun)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hasil chunk new pattern (pattern Pak Indra)\n",
      "\n",
      "True positive =  19\n",
      "False positive =  51\n",
      "False negative =  52\n",
      "\n",
      "Precision =  0.2714285714285714\n",
      "Recall =  0.2676056338028169\n",
      "F1 score =  0.2695035460992907\n"
     ]
    }
   ],
   "source": [
    "# count percentage of verb noun pattern accuracy\n",
    "\n",
    "tp_new_pattern = data['true_new_pattern'].apply(len).sum()\n",
    "fp_new_pattern = data['false_new_pattern'].apply(len).sum()\n",
    "fn_new_pattern = data['unpredicted_new_pattern'].apply(len).sum()\n",
    "precision_new_pattern = tp_new_pattern / (tp_new_pattern + fp_new_pattern)\n",
    "recall_new_pattern = tp_new_pattern / (tp_new_pattern + fn_new_pattern)\n",
    "f1score_new_pattern = 2 * (precision_new_pattern * recall_new_pattern) / (precision_new_pattern + recall_new_pattern)\n",
    "\n",
    "print(\"Hasil chunk new pattern (pattern Pak Indra)\\n\")\n",
    "print(\"True positive = \", tp_new_pattern)\n",
    "print(\"False positive = \", fp_new_pattern)\n",
    "print(\"False negative = \", fn_new_pattern)\n",
    "print(\"\\nPrecision = \", precision_new_pattern)\n",
    "print(\"Recall = \", recall_new_pattern)\n",
    "print(\"F1 score = \", f1score_new_pattern)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hasile\n",
    "\n",
    "data.to_excel('export_result/accuration_test_result.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
