{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\hp\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.chunk import RegexpParser\n",
    "from nltk import word_tokenize, pos_tag\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "string.punctuation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title EN</th>\n",
       "      <th>Tasks include</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Legislators</td>\n",
       "      <td>Tasks include -\\n(a)  presiding over or partic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Senior Government Officials</td>\n",
       "      <td>Tasks include -\\n(a)  advising national, state...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Traditional Chiefs and Heads of Villages</td>\n",
       "      <td>Tasks include -\\n(a)  allocating the use of co...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Officials of Special-interest Organizat...</td>\n",
       "      <td>Tasks include -\\n(a)  determining and formulat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Managing Directors and Chief Executives</td>\n",
       "      <td>Tasks include -\\n(a)  planning, directing and ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Title EN  \\\n",
       "3                                        Legislators   \n",
       "4                        Senior Government Officials   \n",
       "5           Traditional Chiefs and Heads of Villages   \n",
       "6  Senior Officials of Special-interest Organizat...   \n",
       "8            Managing Directors and Chief Executives   \n",
       "\n",
       "                                       Tasks include  \n",
       "3  Tasks include -\\n(a)  presiding over or partic...  \n",
       "4  Tasks include -\\n(a)  advising national, state...  \n",
       "5  Tasks include -\\n(a)  allocating the use of co...  \n",
       "6  Tasks include -\\n(a)  determining and formulat...  \n",
       "8  Tasks include -\\n(a)  planning, directing and ...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data\n",
    "\n",
    "data = pd.read_excel('data/isco.xlsx')\n",
    "data = data[data[\"ISCO 08 Code\"].apply(lambda x: len(str(x)) > 3)]\n",
    "data = data[[\"Title EN\", \"Tasks include\"]]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title EN</th>\n",
       "      <th>Tasks include</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Legislators</td>\n",
       "      <td>presiding over or participating in the procee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Senior Government Officials</td>\n",
       "      <td>advising national, state, regional or local g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Traditional Chiefs and Heads of Villages</td>\n",
       "      <td>allocating the use of communal land and other...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Officials of Special-interest Organizat...</td>\n",
       "      <td>determining and formulating the policies, rul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Managing Directors and Chief Executives</td>\n",
       "      <td>planning, directing and coordinating the gene...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Title EN  \\\n",
       "3                                        Legislators   \n",
       "4                        Senior Government Officials   \n",
       "5           Traditional Chiefs and Heads of Villages   \n",
       "6  Senior Officials of Special-interest Organizat...   \n",
       "8            Managing Directors and Chief Executives   \n",
       "\n",
       "                                       Tasks include  \n",
       "3   presiding over or participating in the procee...  \n",
       "4   advising national, state, regional or local g...  \n",
       "5   allocating the use of communal land and other...  \n",
       "6   determining and formulating the policies, rul...  \n",
       "8   planning, directing and coordinating the gene...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove Tasks include -\\n(a) \n",
    "\n",
    "data['Tasks include'] = data['Tasks include'].str.replace('Tasks include -\\n(a) ', '', regex=False)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title EN         0\n",
      "Tasks include    6\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# check missing value\n",
    "\n",
    "print(data.isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46            Services Managers Not Elsewhere Classified\n",
       "195    Process Control Technicians Not Elsewhere Clas...\n",
       "273    Other Artistic and Cultural Associate Professi...\n",
       "367               Sales Workers Not Elsewhere Classified\n",
       "462          Handicraft Workers Not Elsewhere Classified\n",
       "535    Stationary Plant and Machine Operators Not Els...\n",
       "Name: Title EN, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check which occupation have no task description\n",
    "\n",
    "no_task = data[data['Tasks include'].isnull()]['Title EN']\n",
    "no_task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title EN</th>\n",
       "      <th>Tasks include</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Legislators</td>\n",
       "      <td>presiding over or participating in the procee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Senior Government Officials</td>\n",
       "      <td>advising national, state, regional or local g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Traditional Chiefs and Heads of Villages</td>\n",
       "      <td>allocating the use of communal land and other...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Senior Officials of Special-interest Organizat...</td>\n",
       "      <td>determining and formulating the policies, rul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Managing Directors and Chief Executives</td>\n",
       "      <td>planning, directing and coordinating the gene...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Title EN  \\\n",
       "3                                        Legislators   \n",
       "4                        Senior Government Officials   \n",
       "5           Traditional Chiefs and Heads of Villages   \n",
       "6  Senior Officials of Special-interest Organizat...   \n",
       "8            Managing Directors and Chief Executives   \n",
       "\n",
       "                                       Tasks include  \n",
       "3   presiding over or participating in the procee...  \n",
       "4   advising national, state, regional or local g...  \n",
       "5   allocating the use of communal land and other...  \n",
       "6   determining and formulating the policies, rul...  \n",
       "8   planning, directing and coordinating the gene...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove missing value (dihapus karena yang null adalah jenis pekerjaan lainnya)\n",
    "\n",
    "data.dropna(inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3     presiding over or participating in the procee...\n",
       "4     advising national, state, regional or local g...\n",
       "5     allocating the use of communal land and other...\n",
       "6     determining and formulating the policies, rul...\n",
       "8     planning, directing and coordinating the gene...\n",
       "Name: Tasks include, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# lowering text\n",
    "data['Tasks include']= data['Tasks include'].apply(lambda x: x.lower())\n",
    "\n",
    "# Print the updated DataFrame\n",
    "data['Tasks include'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3      [[presiding, over, or, participating, in, the,...\n",
      "4      [[advising, national], [state], [regional, or,...\n",
      "5      [[allocating, the, use, of, communal, land, an...\n",
      "6      [[determining, and, formulating, the, policies...\n",
      "8      [[planning], [directing, and, coordinating, th...\n",
      "                             ...                        \n",
      "604    [[delivering, messages], [packages, and, other...\n",
      "605    [[repairing, broken, windows], [screens], [doo...\n",
      "606    [[filling, storage, areas, of, vending, machin...\n",
      "607    [[cutting, and, collecting, wood, from, forest...\n",
      "608    [[in, such, cases, tasks, would, include, a, s...\n",
      "Name: tokenized, Length: 427, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Function to tokenize each sentence, tokenize each word from sentence, then remove stopwords\n",
    "def tokenize_and_remove_punctuation(text):\n",
    "    # Tokenize each sentence\n",
    "    sentences = re.split(r'(?<=[.!?,;])\\s+', text)\n",
    "    \n",
    "    # Remove punctuation and tokenize each word in each sentence\n",
    "    tokenized_sentences = []\n",
    "    for sentence in sentences:\n",
    "        tokens = word_tokenize(sentence)\n",
    "        # Remove punctuation\n",
    "        tokens = [token for token in tokens if token not in string.punctuation]\n",
    "        tokenized_sentences.append(tokens)\n",
    "    \n",
    "    return tokenized_sentences\n",
    "\n",
    "# Tokenize each sentence and remove punctuation\n",
    "data['tokenized'] = data['Tasks include'].apply(tokenize_and_remove_punctuation)\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(data['tokenized'])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3      [[(presiding, VBG), (over, RP), (or, CC), (par...\n",
      "4      [[(advising, VBG), (national, JJ)], [(state, N...\n",
      "5      [[(allocating, VBG), (the, DT), (use, NN), (of...\n",
      "6      [[(determining, VBG), (and, CC), (formulating,...\n",
      "8      [[(planning, NN)], [(directing, NN), (and, CC)...\n",
      "                             ...                        \n",
      "604    [[(delivering, NN), (messages, NNS)], [(packag...\n",
      "605    [[(repairing, VBG), (broken, JJ), (windows, NN...\n",
      "606    [[(filling, VBG), (storage, NN), (areas, NNS),...\n",
      "607    [[(cutting, VBG), (and, CC), (collecting, VBG)...\n",
      "608    [[(in, IN), (such, JJ), (cases, NNS), (tasks, ...\n",
      "Name: pos_tagged, Length: 427, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Function to perform POS tagging on each token\n",
    "def pos_tag_tokens(tokenized_sentences):\n",
    "    pos_tagged_sentences = []\n",
    "    for sentence_tokens in tokenized_sentences:\n",
    "        pos_tags = pos_tag(sentence_tokens)\n",
    "        pos_tagged_sentences.append(pos_tags)\n",
    "    return pos_tagged_sentences\n",
    "\n",
    "# Perform POS tagging on tokenized sentences\n",
    "data['pos_tagged'] = data['tokenized'].apply(pos_tag_tokens)\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(data['pos_tagged'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3      [[(preside, VBG), (over, RP), (or, CC), (parti...\n",
      "4      [[(advise, VBG), (national, JJ)], [(state, NN)...\n",
      "5      [[(allocate, VBG), (the, DT), (use, NN), (of, ...\n",
      "6      [[(determine, VBG), (and, CC), (formulate, VBG...\n",
      "8      [[(planning, NN)], [(directing, NN), (and, CC)...\n",
      "                             ...                        \n",
      "604    [[(delivering, NN), (message, NNS)], [(package...\n",
      "605    [[(repair, VBG), (broken, JJ), (window, NNS)],...\n",
      "606    [[(fill, VBG), (storage, NN), (area, NNS), (of...\n",
      "607    [[(cut, VBG), (and, CC), (collect, VBG), (wood...\n",
      "608    [[(in, IN), (such, JJ), (case, NNS), (task, NN...\n",
      "Name: lemmatized, Length: 427, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Function to lemmatize tokens\n",
    "def lemmatize_tokens(pos_tagged_sentences):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lemmatized_sentences = []\n",
    "    for sentence_tags in pos_tagged_sentences:\n",
    "        lemmatized_tokens = [(lemmatizer.lemmatize(token, pos=get_wordnet_pos(pos_tag)), pos_tag) for token, pos_tag in sentence_tags]\n",
    "        lemmatized_sentences.append(lemmatized_tokens)\n",
    "    return lemmatized_sentences\n",
    "\n",
    "# Function to map POS tags to WordNet POS tags\n",
    "def get_wordnet_pos(treebank_tag):\n",
    "    if treebank_tag.startswith('J'):\n",
    "        return nltk.corpus.wordnet.ADJ\n",
    "    elif treebank_tag.startswith('V'):\n",
    "        return nltk.corpus.wordnet.VERB\n",
    "    elif treebank_tag.startswith('N'):\n",
    "        return nltk.corpus.wordnet.NOUN\n",
    "    elif treebank_tag.startswith('R'):\n",
    "        return nltk.corpus.wordnet.ADV\n",
    "    else:\n",
    "        return nltk.corpus.wordnet.NOUN  # Default to noun if POS tag not recognized\n",
    "\n",
    "# Lemmatize the tokens in 'pos_tagged_sentences' column\n",
    "data['lemmatized'] = data['pos_tagged'].apply(lemmatize_tokens)\n",
    "\n",
    "# Print the updated DataFrame\n",
    "print(data['lemmatized'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### POS Chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3      [(direct, policy), (repeal, law), (investigate...\n",
       "4      [(include, amendment), (establish, objective),...\n",
       "5              [(settle, dispute), (discipline, member)]\n",
       "6      [(govern, body), (direct, section), (evaluate,...\n",
       "8      [(govern, body), (determine, objective), (mana...\n",
       "                             ...                        \n",
       "604    [(deliver, luggage), (mark, baggage), (attach,...\n",
       "605     [(adjust, door), (replace, tap), (unload, coal)]\n",
       "606    [(fill, storage), (vend, machine), (collect, m...\n",
       "607    [(collect, wood), (visit, forest), (pick, piec...\n",
       "608    [(collect, ticket), (examine, ticket), (verify...\n",
       "Name: chunked_verb_noun, Length: 427, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pos chunk verb noun pairs\n",
    "\n",
    "def extract_verb_noun_pairs(tagged_texts):\n",
    "    chunks = []\n",
    "    for tagged_sentence in tagged_texts:\n",
    "        result = filter_verb_noun_pairs(tagged_sentence)\n",
    "        chunks.append(result)\n",
    "    chunks = [item for sublist in chunks for item in sublist]\n",
    "    return chunks\n",
    "\n",
    "def filter_verb_noun_pairs(tagged_sentence):\n",
    "    verb_noun_pairs = []\n",
    "    for i in range(len(tagged_sentence) - 1):\n",
    "        word, tag = tagged_sentence[i]\n",
    "        next_word, next_tag = tagged_sentence[i + 1]\n",
    "        if tag.startswith('VB') and next_tag.startswith('NN'):\n",
    "            verb = word\n",
    "            noun = next_word\n",
    "            verb_noun_pairs.append((verb, noun))\n",
    "    return verb_noun_pairs\n",
    "\n",
    "# Apply chunking and extraction to the 'tagged_sentences' column\n",
    "data['chunked_verb_noun'] = data['lemmatized'].apply(extract_verb_noun_pairs)\n",
    "\n",
    "# Print the resulting DataFrame with chunked data\n",
    "data['chunked_verb_noun']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n",
      "Warning: parsing empty text\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3      [(participate, in, the, proceeding), (direct, ...\n",
       "4      [(advise, on, the, preparation), (include, ame...\n",
       "5      [(allocate, the, use), (settle, dispute), (dis...\n",
       "6      [(formulate, the, policy), (review, the, opera...\n",
       "8      [(review, the, operation), (govern, body), (de...\n",
       "                             ...                        \n",
       "604    [(deliver, luggage), (mark, baggage), (attach,...\n",
       "605    [(adjust, door), (replace, tap, washer), (put,...\n",
       "606    [(fill, storage, area), (vend, machine), (coll...\n",
       "607    [(collect, wood), (visit, forest), (pick, piec...\n",
       "608    [(include, a, selling, admission, ticket), (co...\n",
       "Name: chunked_new_pattern, Length: 427, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# POS chunk new pattern (Pak Indra)\n",
    "\n",
    "# define pattern\n",
    "pattern = r'''Chunk: {(<ADJ|VB\\w*>+<\\.|RP|IN|CC|PRP\\w*>*<DT>*<NN\\w*|RB\\w*>+)+}'''\n",
    "chunk_parser = RegexpParser(pattern)\n",
    "\n",
    "def extract(tagged_texts):\n",
    "    chunks = []\n",
    "    for tagged_text in tagged_texts:\n",
    "        tree = chunk_parser.parse(tagged_text)\n",
    "        tree = extract_chunks(tree)\n",
    "        tree = trees_to_tuples(tree)\n",
    "        chunks.append(tree)\n",
    "    chunks = [item for sublist in chunks for item in sublist]\n",
    "    return chunks\n",
    "\n",
    "def extract_chunks(tree):\n",
    "    chunks = []\n",
    "    \n",
    "    if isinstance(tree, nltk.Tree):\n",
    "        if tree.label() != 'S':  # Exclude sentence-level chunks if any\n",
    "            chunks.append(tree)\n",
    "        for subtree in tree:\n",
    "            chunks.extend(extract_chunks(subtree))\n",
    "    \n",
    "    return chunks\n",
    "\n",
    "def trees_to_tuples(tree_list):\n",
    "    tuple_list = [tuple(leaf[0] for leaf in tree.leaves()) for tree in tree_list]\n",
    "    return tuple_list\n",
    "\n",
    "# Apply chunking and extraction to the 'tagged_sentences' column\n",
    "data['chunked_new_pattern'] = data['lemmatized'].apply(extract)\n",
    "\n",
    "# Print the resulting DataFrame with chunked data\n",
    "data['chunked_new_pattern']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export Result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # hasile\n",
    "\n",
    "# patent_task = data[[\"title_and_abstract\", \"chunked_verb_noun\", \"chunked_new_pattern\"]]\n",
    "# patent_task.to_excel('export_result/chunk2.xlsx', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
